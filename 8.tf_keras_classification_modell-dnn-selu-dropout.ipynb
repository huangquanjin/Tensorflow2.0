{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200315\n",
      "sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "pandas 1.0.3\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.2.0-dev20200315\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 读取keras中的进阶版mnist数据集\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "# 加载数据集，切分为训练集和测试集\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# 从训练集中将后五千张作为验证集，前五千张作为训练集\n",
    "# [:5000]默认从头开始，从头开始取5000个\n",
    "# [5000:]从第5001开始，结束位置默认为最后\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "# 打印这些数据集的大小\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化 x = (x- u) / std   (0,1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# x_train:[None, 28, 28] 三维的--> [None, 784] \n",
    "scaler = StandardScaler()\n",
    "# fit_transform要求为二维矩阵，因此需要先转换\n",
    "# 要进行除法，因此先转化为浮点型\n",
    "# x_train是三维矩阵[None,28,28]，先将其转换为二维矩阵[None,784],再将其转回三维矩阵\n",
    "# reshape（-1， 1）转化为一列(-1代表不确定几行)\n",
    "# fit: 求得训练集的均值、方差、最大值、最小值等训练集固有的属性\n",
    "# transform: 在fit的基础上，进行标准化，降维，归一化等操作\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation='relu'),\n",
    "#     keras.layers.Dense(100, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for _ in range(20):\n",
    "    # selu:自带归一化功能的激活函数\n",
    "    model.add(keras.layers.Dense(100,activation=\"selu\"))\n",
    "# 在最后几层添加dropout，防止过拟合,rate表示丢掉神经元的比例\n",
    "# AlphaDropout比Dropout的优势：\n",
    "# 1.激活值均值与方差不变 2. 归一化性质也不变\n",
    "model.add(keras.layers.AlphaDropout(rate=0.5))\n",
    "# model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C728C65B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C728C65B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   2/1719 [..............................] - ETA: 14:19 - loss: 2.6315 - accuracy: 0.1719WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.494384). Check your callbacks.\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.7682WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001C725809D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001C725809D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6842 - accuracy: 0.7690 - val_loss: 0.6753 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4576 - accuracy: 0.8438 - val_loss: 0.5438 - val_accuracy: 0.8616\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4062 - accuracy: 0.8593 - val_loss: 0.4980 - val_accuracy: 0.8732\n",
      "Epoch 4/10\n",
      " 196/1719 [==>...........................] - ETA: 3s - loss: 0.3656 - accuracy: 0.8693"
     ]
    }
   ],
   "source": [
    "# callbacks:Tensorboard, Earlystopping, ModelCheckpoint\n",
    "logdir = os.path.join(\"dnn-selu-dropout2-allbacks\")\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "# 在callbacks文件夹下创建文件。c=os.path.join(a,b),c=a/b\n",
    "output_model_file = os.path.join(logdir,\"fashion_mnist_model.h5\")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                   save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=10,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                   callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    # 将history.history转换为dataframe格式\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5 ))\n",
    "    plt.grid(True)\n",
    "    # gca：get current axes,gcf: get current figure\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# 1.参数众多，训练不充分\n",
    "# 2.梯度消失：链式法则 --》复合函数f(g(x))求导\n",
    "# 批归一化缓解ti'du'xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_tensorflow2.0_gpu",
   "language": "python",
   "name": "py36_tensorflow2.0_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
