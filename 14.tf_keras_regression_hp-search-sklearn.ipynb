{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200315\n",
      "sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "pandas 1.0.3\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.2.0-dev20200315\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=7) # test_size=0.25(默认)，可以通过                                   \n",
    "                                                # 这个改变比例\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state=11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023817FFA7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023817FFA7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "317/363 [=========================>....] - ETA: 0s - loss: 1.4331WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818308488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818308488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 0.7252\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6407 - val_loss: 0.6451\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.5857 - val_loss: 0.5881\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5472\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.5084 - val_loss: 0.5264\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.4955 - val_loss: 0.5091\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.4845 - val_loss: 0.4949\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4665 - val_loss: 0.4842\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.4582 - val_loss: 0.4765\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.4495 - val_loss: 0.4673\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.4445 - val_loss: 0.4607\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.4368 - val_loss: 0.4611\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.4398 - val_loss: 0.4522\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.4386 - val_loss: 0.4453\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.4328 - val_loss: 0.4430\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4328 - val_loss: 0.4350\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4189 - val_loss: 0.4298\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.4112 - val_loss: 0.4275\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.4107 - val_loss: 0.4251\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.4111 - val_loss: 0.4203\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4077 - val_loss: 0.4156\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4042 - val_loss: 0.4108\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3965 - val_loss: 0.4081\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3929 - val_loss: 0.4047\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3928 - val_loss: 0.4031\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3903 - val_loss: 0.4005\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3874 - val_loss: 0.3988\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3869 - val_loss: 0.3994\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3896 - val_loss: 0.3938\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3887 - val_loss: 0.3941\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3888 - val_loss: 0.3915\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3807 - val_loss: 0.3880\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3774 - val_loss: 0.3896\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3751 - val_loss: 0.3859\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3764 - val_loss: 0.3879\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3815 - val_loss: 0.3873\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.3812 - val_loss: 0.3847\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3751 - val_loss: 0.3837\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3716 - val_loss: 0.3802\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3695 - val_loss: 0.3810\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3682 - val_loss: 0.3815\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3682 - val_loss: 0.3778\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3682 - val_loss: 0.3769\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3697 - val_loss: 0.3780\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3694 - val_loss: 0.3796\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3710 - val_loss: 0.3765\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3691 - val_loss: 0.3747\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3683 - val_loss: 0.3751\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3651 - val_loss: 0.3737\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3662 - val_loss: 0.3728\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3629 - val_loss: 0.3707\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3598 - val_loss: 0.3672\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3611 - val_loss: 0.3677\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3626 - val_loss: 0.3677\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3576 - val_loss: 0.3674\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3577 - val_loss: 0.3664\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3600 - val_loss: 0.3676\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3618 - val_loss: 0.3644\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3569 - val_loss: 0.3657\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3574 - val_loss: 0.3646\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3551 - val_loss: 0.3653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3552 - val_loss: 0.3629\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3554 - val_loss: 0.3632\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3531 - val_loss: 0.3612\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3532 - val_loss: 0.3643\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3591 - val_loss: 0.3682\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3597\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3589\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3499 - val_loss: 0.3605\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3494 - val_loss: 0.3598\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3489 - val_loss: 0.3607\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3491 - val_loss: 0.3603\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3522 - val_loss: 0.3595\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3603 - val_loss: 0.3598\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3701 - val_loss: 0.3627\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3521 - val_loss: 0.3566\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3473 - val_loss: 0.3576\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3531 - val_loss: 0.3632\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.3532 - val_loss: 0.3543\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# 1.转化为sklearn的model\n",
    "# 2.定义参数集合\n",
    "# 3.搜索参数\n",
    "def build_model(hidden_layers=1, layer_size=30, learning_rate=3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(layer_size, activation='relu',\n",
    "              input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers-1):\n",
    "        model.add(keras.layers.Dense(layer_size, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(\n",
    "    build_model)\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=15, min_delta=1e-2)]\n",
    "history = sklearn_model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                 validation_data =(x_valid_scaled, y_valid),\n",
    "                  callbacks = callbacks\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "245/291 [========================>.....] - ETA: 0s - loss: 1.6777WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198D9A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198D9A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.5272 - val_loss: 0.8315\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7221 - val_loss: 0.7327\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6620 - val_loss: 0.6876\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6258 - val_loss: 0.6496\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5920 - val_loss: 0.6161\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.5874\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5605\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5376\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4988 - val_loss: 0.5175\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.5011\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4843\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4541 - val_loss: 0.4728\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4609\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4524\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4459\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4339\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4265\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4232\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4139\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.4103\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4047\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4006\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3977\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3930\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3878\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.3857\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3833\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3816\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3774\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3763\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3742\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3697\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3700\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3664\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3665\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3634\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3615\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3574\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3555\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3565\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3555\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3527\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3522\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3492\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3505\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.3466\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3459\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3532\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.3420\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3425\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3415\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3395\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3402\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3375\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3414\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3374\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3359\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3347\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3329\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3349\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3335\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3310\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3344\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3291\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3294\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3327\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3285\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3272\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3284\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3257\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3264\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3276\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3257\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3245\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3259\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3225\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3238\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3033\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B76CF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B76CF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/291 [============================>.] - ETA: 0s - loss: 1.5118WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 1.4897 - val_loss: 0.7951\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6477 - val_loss: 0.6434\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.5805\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.5359\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.5030\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4812\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4622\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4510\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4395\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4335\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4237\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4168\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4120\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4064\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4026\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3968\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3940\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3919\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3879\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3877\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3848\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3836\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3775\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3814\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3763\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3715\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3706\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3694\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3797\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3689\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3657\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3624\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3635\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3598\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3589\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3575\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3572\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3592\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3532\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3518\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.3520\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3580\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3500\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3492\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3511\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.3475\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3459\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3461\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3456\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3170 - val_loss: 0.3498\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3552\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3435\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3414\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3410\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3415\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3393\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3409\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3392\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3365\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3408\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3489\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3359\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3466\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3327\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3327\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3351\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.3320\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3367\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3321\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3308\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.3304\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3332\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3359\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3273\n",
      "73/73 [==============================] - 0s 779us/step - loss: 0.3102\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195FCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195FCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "276/291 [===========================>..] - ETA: 0s - loss: 2.1040WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819619D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819619D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 2.0346 - val_loss: 0.9368\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7586 - val_loss: 0.7384\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6550 - val_loss: 0.6799\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6332\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.5909\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 0.5641\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5038 - val_loss: 0.5276\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.5027\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.4861\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4676\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4578\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4463\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4377\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4297\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4252\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4178\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4158\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4080\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4068\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4017\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4006\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3953\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3927\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3895\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3851\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3833\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.3815\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3847\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3766\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3747\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3730\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3713\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3709\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3669\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3680\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3658\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3652\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3638\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.3621\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3591\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3564\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3569\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3550\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3569\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3598\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3499\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.3529\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3546\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3473\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3490\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3456\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3440\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3447\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3424\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3400\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3409\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3389\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3388\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3410\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3371\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3380\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3357\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3340\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3317\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3333\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3320\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3339\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3291\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3320\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3293\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3320\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3266\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3273\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3258\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3251\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3554\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3243\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3218\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.3215\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3261\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3256\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3219\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3228\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3191\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.3225\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3254\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.3302\n",
      "73/73 [==============================] - 0s 656us/step - loss: 0.3305\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819E24BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819E24BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "246/291 [========================>.....] - ETA: 0s - loss: 2.1583WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.9739 - val_loss: 1.0427\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8337 - val_loss: 0.7015\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6320\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5905\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5269 - val_loss: 0.5564\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5029 - val_loss: 0.5264\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.5033\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4843\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4694\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4581\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4489\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4399\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4316\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4259\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4195\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4149\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4118\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4042\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3998\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3956\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3964\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3916\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3947\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3840\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3857\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.3808\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3794\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3764\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3750\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3734\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3730\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3679\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3707\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3642\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3695\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3684\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3646\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3612\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3588\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3569\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3577\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3565\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3542\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3538\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3510\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3491\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3522\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3514\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3473\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3477\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3446\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3450\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3432\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3424\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3437\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3400\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3407\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3390\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3091 - val_loss: 0.3392\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3384\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3484\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3381\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3377\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3419\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3350\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3373\n",
      "73/73 [==============================] - 0s 806us/step - loss: 0.3336\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/291 [==========================>...] - ETA: 0s - loss: 1.7516WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381A4C5620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381A4C5620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 1.6905 - val_loss: 0.9288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7388 - val_loss: 0.7127\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 0.6593\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5872 - val_loss: 0.6178\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.5832\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.5591\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5039 - val_loss: 0.5345\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4847 - val_loss: 0.5129\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4699 - val_loss: 0.4974\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.4832\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4734\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4585\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4555\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4424\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4395\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4260\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4219\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4144\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4095\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4065\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4024\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3983\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3933\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3948\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3879\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3851\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3841\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3802\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3839\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.3763\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3746\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3759\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3779\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3754\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3678\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3709\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3663\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3659\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3637\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3612\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3623\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3583\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3586\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3632\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3557\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3580\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3554\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3528\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3504\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3492\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3490\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3478\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3462\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3464\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3488\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3486\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3488\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3470\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3479\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3442\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3435\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3403\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3400\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3397\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.3410\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3406\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3379\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3373\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3365\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3345\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3343\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3342\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3626\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3368\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.3352\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3391\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BD09048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BD09048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/291 [============================>.] - ETA: 0s - loss: 2.9669WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BA5E7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BA5E7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.9268 - val_loss: 1.5809\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.2021 - val_loss: 1.0145\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8808 - val_loss: 0.8379\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7532 - val_loss: 0.7566\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6922 - val_loss: 0.7139\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6578 - val_loss: 0.6856\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6355 - val_loss: 0.6651\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6475\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6324\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5906 - val_loss: 0.6185\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5779 - val_loss: 0.6062\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.5947\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5839\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5482 - val_loss: 0.5740\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5652\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.5556\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5474\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5397\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.5333\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5042 - val_loss: 0.5255\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5193\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5132\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5073\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4827 - val_loss: 0.5018\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.4966\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4922\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4879\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4836\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4628 - val_loss: 0.4789\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4751\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4717\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4678\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4644\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4609\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4576\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4549\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4519\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4486\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4460\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4434\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4404\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4380\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4360\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4336\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4311\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4289\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4269\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4252\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4230\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4217\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4197\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4176\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4159\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4142\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4128\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4112\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4098\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.4083\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4070\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4054\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4048\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4032\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4019\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.4009\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3996\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3986\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3977\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3966\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3957\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3945\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3927\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3917\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3906\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3900\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3897\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3880\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3875\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3867\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3862\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3854\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3843\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3843\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3828\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3826\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3818\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3814\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3808\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3801\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3794\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3794\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3782\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3775\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3770\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3763\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3756\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3759\n",
      "73/73 [==============================] - 0s 643us/step - loss: 0.3496\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B79D730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B79D730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "256/291 [=========================>....] - ETA: 0s - loss: 4.2787WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.1356 - val_loss: 2.8378\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.9952 - val_loss: 1.6456\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3377 - val_loss: 1.2495\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0634 - val_loss: 1.0449\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9077 - val_loss: 0.9072\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8028 - val_loss: 0.8164\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7357 - val_loss: 0.7587\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6938 - val_loss: 0.7210\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6946\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.6732\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6563\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6292\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.6176\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5712 - val_loss: 0.6075\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.5980\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5518 - val_loss: 0.5881\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5450 - val_loss: 0.5797\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5715\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5641\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5573\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5131 - val_loss: 0.5505\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5439\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.5369\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4952 - val_loss: 0.5312\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.5254\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4868 - val_loss: 0.5205\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.5149\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.5101\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.5063\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4650 - val_loss: 0.5012\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4976\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 0.4931\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 0.4892\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4863\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4823\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.4791\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4749\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4379 - val_loss: 0.4733\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4693\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4677\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4658\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4615\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4589\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4573\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4531\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4517\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4485\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4481\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4451\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4447\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4423\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4388\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4359\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.4352\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.4319\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4305\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4285\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4274\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4259\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4225\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4238\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.4194\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4179\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4175\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.4178\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4140\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.4148\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4149\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4117\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.4085\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4057\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4055\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.4037\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4044\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.4029\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4000\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3984\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3996\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3965\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4002\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3946\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3929\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3924\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3913\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3902\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3901\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3896\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3886\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3872\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3856\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.3844\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3837\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3827\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3835\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3818\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3800\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3794\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3785\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3779\n",
      "73/73 [==============================] - 0s 656us/step - loss: 0.3637\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819455E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819455E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "257/291 [=========================>....] - ETA: 0s - loss: 3.2878WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BDC49D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BDC49D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 3.1422 - val_loss: 1.7336\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.2739 - val_loss: 1.0794\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9394 - val_loss: 0.8832\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8060 - val_loss: 0.7972\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7359 - val_loss: 0.7495\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6965 - val_loss: 0.7188\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6679 - val_loss: 0.6961\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6434 - val_loss: 0.6784\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 0.6635\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6500\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6379\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5879 - val_loss: 0.6270\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 0.6176\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.6072\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5641 - val_loss: 0.5987\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5527 - val_loss: 0.5900\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5819\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5387 - val_loss: 0.5748\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.5672\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5608\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5539\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.5477\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5418\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5359\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.5303\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4998 - val_loss: 0.5246\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.5191\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4862 - val_loss: 0.5142\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.5092\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.5045\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.5006\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4961\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4921\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4880\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.4844\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4583 - val_loss: 0.4808\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4774\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4745\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4720\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4684\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4661\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.4636\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4607\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4585\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4560\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4541\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4515\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4495\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4474\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4455\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4441\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4422\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4403\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4385\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4371\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.4357\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.4334\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4320\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4305\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4290\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4274\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4261\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4243\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4236\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4220\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4210\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.4193\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4184\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4173\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4163\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4144\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4132\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4122\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4112\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4098\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4085\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4077\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4068\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4058\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4046\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4033\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.4025\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4020\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4004\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3996\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3984\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3979\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3959\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3958\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3949\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3937\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3931\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3923\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.3914\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3913\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3913\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3901\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3891\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3890\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3789\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "280/291 [===========================>..] - ETA: 0s - loss: 2.7286WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238197707B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238197707B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.6728 - val_loss: 1.5825\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.2093 - val_loss: 1.1223\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9365 - val_loss: 0.9117\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7877 - val_loss: 0.7954\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7063 - val_loss: 0.7315\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6565 - val_loss: 0.6926\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6236 - val_loss: 0.6658\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6440\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5848 - val_loss: 0.6272\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5649 - val_loss: 0.6101\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.5945\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.5812\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5692\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5125 - val_loss: 0.5565\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5016 - val_loss: 0.5456\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4921 - val_loss: 0.5353\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4833 - val_loss: 0.5242\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.5169\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.5062\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4980\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 0.4915\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4844\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4781\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4715\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4659\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4606\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4562\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.4506\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4471\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4429\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.4388\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4349\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4326\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4299\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4263\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4237\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4214\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4188\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4170\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4152\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4132\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4120\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4095\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.4080\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4058\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.4043\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4037\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4024\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4008\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4004\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3983\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3973\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3962\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3950\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3942\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3929\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3923\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3921\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.3912\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3890\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3886\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3884\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3874\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3868\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3857\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3855\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3849\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3843\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3855\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.3831\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3818\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3815\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3813\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3804\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3812\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3799\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3799\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3789\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3782\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3778\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3773\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3765\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3761\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3754\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3758\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3766\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816D08E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816D08E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "284/291 [============================>.] - ETA: 0s - loss: 3.4407WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.4116 - val_loss: 2.1214\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4962 - val_loss: 1.2066\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9968 - val_loss: 0.9113\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7908 - val_loss: 0.7682\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6906 - val_loss: 0.7004\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6376 - val_loss: 0.6623\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6370\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.6184\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5641 - val_loss: 0.6034\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5904\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5787\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5685\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5583\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.5491\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5018 - val_loss: 0.5406\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4947 - val_loss: 0.5326\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4874 - val_loss: 0.5255\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4817 - val_loss: 0.5184\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.5121\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4703 - val_loss: 0.5058\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.5002\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4624 - val_loss: 0.4942\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4892\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4845\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4801\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4756\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.4712\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4678\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4641\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4610\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4572\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4543\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4514\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4489\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.4461\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4436\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4423\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4393\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4370\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4350\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4334\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4313\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4302\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4272\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4259\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4239\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4224\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4204\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4212\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4191\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4163\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4146\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4140\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4122\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4112\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4099\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4081\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4069\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4057\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.4044\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4032\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4022\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4014\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4009\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4004\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3982\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3984\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3966\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3955\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3941\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3932\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3923\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3926\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3910\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3898\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3886\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3880\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3877\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3869\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3868\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3847\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3842\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3833\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3830\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3825\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3817\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3810\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3802\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3792\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3793\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3776\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3772\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3766\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3761\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3760\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3754\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3818\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B99FE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B99FE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "264/291 [==========================>...] - ETA: 0s - loss: 1.5743WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238183A0268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238183A0268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4965 - val_loss: 0.8422\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.7259 - val_loss: 0.7277\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.6468 - val_loss: 0.6683\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5924 - val_loss: 0.6072\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5524 - val_loss: 0.5700\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5266 - val_loss: 0.5432\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5025 - val_loss: 0.5184\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4876 - val_loss: 0.5060\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4760 - val_loss: 0.4875\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4653 - val_loss: 0.4824\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4560 - val_loss: 0.4724\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4527 - val_loss: 0.4637\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4462 - val_loss: 0.4588\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4420 - val_loss: 0.4548\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.4363 - val_loss: 0.4490\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 854us/step - loss: 0.4338 - val_loss: 0.4453\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4297 - val_loss: 0.4726\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4295 - val_loss: 0.4395\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4232 - val_loss: 0.4356\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4221 - val_loss: 0.4362\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4180 - val_loss: 0.4304\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4155 - val_loss: 0.4289\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4124 - val_loss: 0.4237\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4096 - val_loss: 0.4243\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4091 - val_loss: 0.4202\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4063 - val_loss: 0.4166\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.4047 - val_loss: 0.4156\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.4026 - val_loss: 0.4128\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.4007 - val_loss: 0.4120\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3986 - val_loss: 0.4099\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3977 - val_loss: 0.4074\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3963 - val_loss: 0.4067\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3943 - val_loss: 0.4060\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3944 - val_loss: 0.4020\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 846us/step - loss: 0.3904 - val_loss: 0.4000\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3883 - val_loss: 0.3987\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3874 - val_loss: 0.3981\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 854us/step - loss: 0.3859 - val_loss: 0.3959\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 843us/step - loss: 0.3847 - val_loss: 0.3963\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3844 - val_loss: 0.3950\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 843us/step - loss: 0.3832 - val_loss: 0.3925\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.3807 - val_loss: 0.3907\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.3805 - val_loss: 0.3903\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.3792 - val_loss: 0.3906\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3779 - val_loss: 0.3875\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3777 - val_loss: 0.3867\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3753 - val_loss: 0.3858\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.3764 - val_loss: 0.3848\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3746 - val_loss: 0.3841\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3734 - val_loss: 0.3866\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3727 - val_loss: 0.3832\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3721 - val_loss: 0.3815\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3715 - val_loss: 0.3791\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3701 - val_loss: 0.3792\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3695 - val_loss: 0.3792\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3690 - val_loss: 0.3774\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3683 - val_loss: 0.3850\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3679 - val_loss: 0.3791\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3662 - val_loss: 0.3755\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3662 - val_loss: 0.3772\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3713 - val_loss: 0.3745\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3653 - val_loss: 0.3734\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3631 - val_loss: 0.3736\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3639 - val_loss: 0.3747\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3710\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 942us/step - loss: 0.3618 - val_loss: 0.3714\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3611 - val_loss: 0.3695\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3606 - val_loss: 0.3710\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3616 - val_loss: 0.3695\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3594 - val_loss: 0.3697\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3594 - val_loss: 0.3683\n",
      "73/73 [==============================] - 0s 520us/step - loss: 0.3426\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B99F378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B99F378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/291 [========================>.....] - ETA: 0s - loss: 1.5051WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023817FFA2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023817FFA2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.6427 - val_loss: 0.8723\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.7710 - val_loss: 0.6655\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.5943 - val_loss: 0.6254\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5572 - val_loss: 0.5873\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5321 - val_loss: 0.5624\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5096 - val_loss: 0.5424\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4942 - val_loss: 0.5259\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4808 - val_loss: 0.5122\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.4723 - val_loss: 0.5024\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4624 - val_loss: 0.4925\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4585 - val_loss: 0.4861\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.4563 - val_loss: 0.4848\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.4507 - val_loss: 0.4741\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.4435 - val_loss: 0.4696\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4388 - val_loss: 0.4648\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4337 - val_loss: 0.4618\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4316 - val_loss: 0.4574\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4289 - val_loss: 0.4532\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4245 - val_loss: 0.4489\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4214 - val_loss: 0.4455\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4189 - val_loss: 0.4420\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4162 - val_loss: 0.4390\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4128 - val_loss: 0.4363\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4105 - val_loss: 0.4344\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4089 - val_loss: 0.4307\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4069 - val_loss: 0.4299\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4057 - val_loss: 0.4258\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4024 - val_loss: 0.4252\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3998 - val_loss: 0.4230\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3982 - val_loss: 0.4195\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3974 - val_loss: 0.4170\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3940 - val_loss: 0.4155\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3932 - val_loss: 0.4138\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3913 - val_loss: 0.4122\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3896 - val_loss: 0.4098\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3887 - val_loss: 0.4069\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3859 - val_loss: 0.4072\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3860 - val_loss: 0.4049\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3848 - val_loss: 0.4056\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3841 - val_loss: 0.4029\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3817 - val_loss: 0.4006\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3805 - val_loss: 0.3983\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3802 - val_loss: 0.3985\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.3799 - val_loss: 0.3948\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.3773 - val_loss: 0.3947\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3759 - val_loss: 0.3929\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3743 - val_loss: 0.3934\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3752 - val_loss: 0.3912\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3752 - val_loss: 0.3901\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3732 - val_loss: 0.3887\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3724 - val_loss: 0.3879\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3713 - val_loss: 0.3896\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3696 - val_loss: 0.3872\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3687 - val_loss: 0.3855\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 936us/step - loss: 0.3690 - val_loss: 0.3860\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3664 - val_loss: 0.3826\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3655 - val_loss: 0.3845\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3659 - val_loss: 0.3822\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3652 - val_loss: 0.3826\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3639 - val_loss: 0.3816\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.3626 - val_loss: 0.3789\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3632 - val_loss: 0.3838\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3619 - val_loss: 0.3789\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3632 - val_loss: 0.3783\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3609 - val_loss: 0.3780\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3609 - val_loss: 0.3762\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3590 - val_loss: 0.3769\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3599 - val_loss: 0.3753\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3594 - val_loss: 0.3752\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3587 - val_loss: 0.3742\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3586 - val_loss: 0.3727\n",
      "73/73 [==============================] - 0s 561us/step - loss: 0.3579\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "243/291 [========================>.....] - ETA: 0s - loss: 1.3739WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CF82B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CF82B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.2615 - val_loss: 0.7425\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.6377 - val_loss: 0.6492\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5773 - val_loss: 0.6009\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5421 - val_loss: 0.5652\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5139 - val_loss: 0.5402\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4985 - val_loss: 0.5201\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4869 - val_loss: 0.5059\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4725 - val_loss: 0.4932\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4623 - val_loss: 0.4829\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4800\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4500 - val_loss: 0.4665\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4413 - val_loss: 0.4598\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4346 - val_loss: 0.4536\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4284 - val_loss: 0.4455\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.4242 - val_loss: 0.4412\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4232 - val_loss: 0.4363\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4168 - val_loss: 0.4329\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4143 - val_loss: 0.4282\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4105 - val_loss: 0.4268\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4092 - val_loss: 0.4213\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4043 - val_loss: 0.4188\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4030 - val_loss: 0.4155\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3988 - val_loss: 0.4135\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3967 - val_loss: 0.4107\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3953 - val_loss: 0.4077\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3922 - val_loss: 0.4090\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3919 - val_loss: 0.4049\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3885 - val_loss: 0.4020\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 902us/step - loss: 0.3870 - val_loss: 0.4013\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3868 - val_loss: 0.4013\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3835 - val_loss: 0.3968\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3855 - val_loss: 0.3958\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3821 - val_loss: 0.3957\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3793 - val_loss: 0.3943\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3793 - val_loss: 0.3930\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3783 - val_loss: 0.3928\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3762 - val_loss: 0.3933\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3769 - val_loss: 0.3878\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3737 - val_loss: 0.3901\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3726 - val_loss: 0.3871\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3719 - val_loss: 0.3856\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3705 - val_loss: 0.3856\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3693 - val_loss: 0.3848\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 891us/step - loss: 0.3696 - val_loss: 0.3943\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3662 - val_loss: 0.3841\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3653 - val_loss: 0.3812\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3654 - val_loss: 0.3835\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3655 - val_loss: 0.3812\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3639 - val_loss: 0.3797\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3635 - val_loss: 0.3766\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3621 - val_loss: 0.3772\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3618 - val_loss: 0.3756\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3609 - val_loss: 0.3753\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3597 - val_loss: 0.3772\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3594 - val_loss: 0.3762\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3574 - val_loss: 0.3732\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3568 - val_loss: 0.3779\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3584 - val_loss: 0.3763\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3556 - val_loss: 0.3733\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3554 - val_loss: 0.3735\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3545 - val_loss: 0.3717\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3544 - val_loss: 0.3716\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3535 - val_loss: 0.3702\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3554 - val_loss: 0.3697\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3524 - val_loss: 0.3887\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3537 - val_loss: 0.3698\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3542 - val_loss: 0.3696\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3537 - val_loss: 0.3692\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 902us/step - loss: 0.3518 - val_loss: 0.3664\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3497 - val_loss: 0.3692\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3488 - val_loss: 0.3674\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.3565\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023818437598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023818437598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "255/291 [=========================>....] - ETA: 0s - loss: 1.5745WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BA5E158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BA5E158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4675 - val_loss: 0.8170\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.7200 - val_loss: 0.7301\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.6172 - val_loss: 0.6717\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5683 - val_loss: 0.6190\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5364 - val_loss: 0.5887\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5166 - val_loss: 0.5643\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4968 - val_loss: 0.5443\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4826 - val_loss: 0.5285\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4723 - val_loss: 0.5135\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4625 - val_loss: 0.5054\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.4588 - val_loss: 0.4913\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4493 - val_loss: 0.4828\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4446 - val_loss: 0.4744\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4399 - val_loss: 0.4694\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4349 - val_loss: 0.4669\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4313 - val_loss: 0.4612\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4281 - val_loss: 0.4594\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4254 - val_loss: 0.4524\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4213 - val_loss: 0.4496\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4197 - val_loss: 0.4467\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4158 - val_loss: 0.4429\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4133 - val_loss: 0.4411\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4116 - val_loss: 0.4381\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4086 - val_loss: 0.4331\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4070 - val_loss: 0.4314\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4041 - val_loss: 0.4289\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4024 - val_loss: 0.4273\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3998 - val_loss: 0.4254\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3994 - val_loss: 0.4232\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3966 - val_loss: 0.4194\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3948 - val_loss: 0.4187\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3928 - val_loss: 0.4175\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 898us/step - loss: 0.3913 - val_loss: 0.4141\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3896 - val_loss: 0.4139\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3882 - val_loss: 0.4113\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3874 - val_loss: 0.4090\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3867 - val_loss: 0.4093\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3850 - val_loss: 0.4066\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3825 - val_loss: 0.4057\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3824 - val_loss: 0.4066\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3815 - val_loss: 0.4017\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3796 - val_loss: 0.4044\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3790 - val_loss: 0.4001\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3771 - val_loss: 0.3988\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3770 - val_loss: 0.3973\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3747 - val_loss: 0.3980\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3749 - val_loss: 0.3970\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3729 - val_loss: 0.3937\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3716 - val_loss: 0.3916\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3707 - val_loss: 0.3924\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3704 - val_loss: 0.3916\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3899\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3687 - val_loss: 0.3928\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3676 - val_loss: 0.3885\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3666 - val_loss: 0.3874\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3659 - val_loss: 0.3884\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3663 - val_loss: 0.3857\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3651 - val_loss: 0.3849\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3631 - val_loss: 0.3842\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3616 - val_loss: 0.3844\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3623 - val_loss: 0.3853\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3611 - val_loss: 0.3832\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3602 - val_loss: 0.3844\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3597 - val_loss: 0.3818\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.3768\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198D9598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198D9598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "266/291 [==========================>...] - ETA: 0s - loss: 1.4321WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818437A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818437A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3748 - val_loss: 0.8065\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.6987 - val_loss: 0.7230\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.6345 - val_loss: 0.6682\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5970 - val_loss: 0.6375\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5656 - val_loss: 0.6018\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5449 - val_loss: 0.5738\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.5244 - val_loss: 0.5561\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.5005 - val_loss: 0.5473\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4959 - val_loss: 0.5797\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4807 - val_loss: 0.5137\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4646 - val_loss: 0.5104\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.4656 - val_loss: 0.4893\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.4564 - val_loss: 0.4878\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4531 - val_loss: 0.4841\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4429 - val_loss: 0.4694\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.4316 - val_loss: 0.4608\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4263 - val_loss: 0.4584\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.4319 - val_loss: 0.4571\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4261 - val_loss: 0.4505\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4197 - val_loss: 0.4451\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4115 - val_loss: 0.4413\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4125 - val_loss: 0.4407\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4075 - val_loss: 0.4353\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4023 - val_loss: 0.4376\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4091 - val_loss: 0.4336\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4120 - val_loss: 0.4346\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4057 - val_loss: 0.4244\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3963 - val_loss: 0.4258\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 881us/step - loss: 0.3958 - val_loss: 0.4193\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3929 - val_loss: 0.4192\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3878 - val_loss: 0.4136\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3852 - val_loss: 0.4211\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3927 - val_loss: 0.4195\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3873 - val_loss: 0.4129\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.3860 - val_loss: 0.4095\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3845 - val_loss: 0.4096\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3828 - val_loss: 0.4085\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3807 - val_loss: 0.4022\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.3813 - val_loss: 0.3999\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.3755 - val_loss: 0.4014\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3734 - val_loss: 0.3991\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3719 - val_loss: 0.4010\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3703 - val_loss: 0.3964\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3701 - val_loss: 0.3967\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3684 - val_loss: 0.3951\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3686 - val_loss: 0.3980\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3734 - val_loss: 0.3943\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3695 - val_loss: 0.3943\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3706 - val_loss: 0.3959\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3678 - val_loss: 0.3933\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3646 - val_loss: 0.3961\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3663 - val_loss: 0.3893\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3661 - val_loss: 0.3884\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3641 - val_loss: 0.3918\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3639 - val_loss: 0.3837\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3634 - val_loss: 0.3837\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3604 - val_loss: 0.3852\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3608 - val_loss: 0.3828\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3605 - val_loss: 0.3871\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3612 - val_loss: 0.3860\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.3613 - val_loss: 0.3830\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3570 - val_loss: 0.3819\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3594 - val_loss: 0.3789\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3593 - val_loss: 0.3802\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3600 - val_loss: 0.3785\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3569 - val_loss: 0.3790\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3577 - val_loss: 0.3789\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3560 - val_loss: 0.3772\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.3534 - val_loss: 0.3799\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3559 - val_loss: 0.3789\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.3848\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381A4C5950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381A4C5950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "252/291 [========================>.....] - ETA: 0s - loss: 3.2827WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B99FF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B99FF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.2114 - val_loss: 2.4155\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 1.8629 - val_loss: 1.5368\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 1.2774 - val_loss: 1.1549\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 1.0104 - val_loss: 0.9829\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.8836 - val_loss: 0.9013\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.8195 - val_loss: 0.8564\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.7812 - val_loss: 0.8270\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7535 - val_loss: 0.8046\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.7334 - val_loss: 0.7862\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.7163 - val_loss: 0.7702\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.7020 - val_loss: 0.7556\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.6889 - val_loss: 0.7425\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.6812 - val_loss: 0.7302\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.6699 - val_loss: 0.7190\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.6574 - val_loss: 0.7083\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6476 - val_loss: 0.6983\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6396 - val_loss: 0.6888\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.6318 - val_loss: 0.6797\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 936us/step - loss: 0.6240 - val_loss: 0.6714\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.6194 - val_loss: 0.6633\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.6095 - val_loss: 0.6557\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.6034 - val_loss: 0.6486\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5964 - val_loss: 0.6416\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5909 - val_loss: 0.6350\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5846 - val_loss: 0.6286\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5806 - val_loss: 0.6227\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.5740 - val_loss: 0.6171\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5691 - val_loss: 0.6115\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5646 - val_loss: 0.6062\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5607 - val_loss: 0.6011\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.5558 - val_loss: 0.5964\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.5518 - val_loss: 0.5919\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5508 - val_loss: 0.5873\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5444 - val_loss: 0.5831\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5425 - val_loss: 0.5789\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5372 - val_loss: 0.5748\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5339 - val_loss: 0.5713\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5309 - val_loss: 0.5678\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5303 - val_loss: 0.5643\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.5248 - val_loss: 0.5609\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.5221 - val_loss: 0.5578\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5201 - val_loss: 0.5548\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5167 - val_loss: 0.5517\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.5158 - val_loss: 0.5489\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5120 - val_loss: 0.5460\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5106 - val_loss: 0.5435\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.5112 - val_loss: 0.5412\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5061 - val_loss: 0.5387\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5050 - val_loss: 0.5363\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.5017 - val_loss: 0.5340\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.5029 - val_loss: 0.5319\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4982 - val_loss: 0.5295\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4970 - val_loss: 0.5275\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4951 - val_loss: 0.5255\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4946 - val_loss: 0.5233\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4923 - val_loss: 0.5215\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4900 - val_loss: 0.5196\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4884 - val_loss: 0.5179\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4873 - val_loss: 0.5162\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4857 - val_loss: 0.5146\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 950us/step - loss: 0.4847 - val_loss: 0.5129\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4830 - val_loss: 0.5113\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4833 - val_loss: 0.5098\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4809 - val_loss: 0.5084\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4799 - val_loss: 0.5070\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4780 - val_loss: 0.5056\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4775 - val_loss: 0.5042\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.4753 - val_loss: 0.5029\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4749 - val_loss: 0.5015\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4732 - val_loss: 0.5002\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4722 - val_loss: 0.4991\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4743 - val_loss: 0.4979\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4704 - val_loss: 0.4967\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4701 - val_loss: 0.4955\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4688 - val_loss: 0.4943\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4678 - val_loss: 0.4931\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4671 - val_loss: 0.4920\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4664 - val_loss: 0.4909\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4644 - val_loss: 0.4899\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4644 - val_loss: 0.4889\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4622 - val_loss: 0.4879\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4617 - val_loss: 0.4869\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4611 - val_loss: 0.4860\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4611 - val_loss: 0.4849\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4597 - val_loss: 0.4839\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4592 - val_loss: 0.4831\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4580 - val_loss: 0.4822\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4568 - val_loss: 0.4812\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4576 - val_loss: 0.4803\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4572 - val_loss: 0.4794\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4555 - val_loss: 0.4788\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4551 - val_loss: 0.4778\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4540 - val_loss: 0.4770\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4556 - val_loss: 0.4761\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4529 - val_loss: 0.4753\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4516 - val_loss: 0.4745\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4506 - val_loss: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4557 - val_loss: 0.4729\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4491 - val_loss: 0.4721\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4484 - val_loss: 0.4715\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.4118\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CE51D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CE51D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/291 [========================>.....] - ETA: 0s - loss: 3.8477WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.6197 - val_loss: 2.5426\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 1.8962 - val_loss: 1.5497\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 1.2658 - val_loss: 1.1401\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.9966 - val_loss: 0.9555\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.8647 - val_loss: 0.8677\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.8021 - val_loss: 0.8207\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.7625 - val_loss: 0.7916\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.7386 - val_loss: 0.7700\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.7194 - val_loss: 0.7525\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.7015 - val_loss: 0.7371\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.6862 - val_loss: 0.7229\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.6729 - val_loss: 0.7095\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.6607 - val_loss: 0.6970\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.6478 - val_loss: 0.6852\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6385 - val_loss: 0.6736\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.6263 - val_loss: 0.6628\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6525\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.6117 - val_loss: 0.6425\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.5968 - val_loss: 0.6332\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5889 - val_loss: 0.6244\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.5806 - val_loss: 0.6159\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.5729 - val_loss: 0.6082\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.5658 - val_loss: 0.6006\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.5583 - val_loss: 0.5936\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5513 - val_loss: 0.5868\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.5453 - val_loss: 0.5804\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5415 - val_loss: 0.5744\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5339 - val_loss: 0.5690\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5289 - val_loss: 0.5633\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5243 - val_loss: 0.5578\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5197 - val_loss: 0.5532\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5154 - val_loss: 0.5486\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.5110 - val_loss: 0.5443\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5080 - val_loss: 0.5398\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5040 - val_loss: 0.5359\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.5002 - val_loss: 0.5321\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4967 - val_loss: 0.5285\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4945 - val_loss: 0.5252\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4905 - val_loss: 0.5220\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4876 - val_loss: 0.5188\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4884 - val_loss: 0.5159\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4833 - val_loss: 0.5129\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4812 - val_loss: 0.5101\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4793 - val_loss: 0.5075\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4752 - val_loss: 0.5053\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4737 - val_loss: 0.5035\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4714 - val_loss: 0.5011\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4725 - val_loss: 0.4989\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4675 - val_loss: 0.4965\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4662 - val_loss: 0.4943\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4647 - val_loss: 0.4925\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4632 - val_loss: 0.4902\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4642 - val_loss: 0.4885\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4595 - val_loss: 0.4866\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 902us/step - loss: 0.4582 - val_loss: 0.4854\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.4567 - val_loss: 0.4840\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4590 - val_loss: 0.4823\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 919us/step - loss: 0.4540 - val_loss: 0.4813\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4532 - val_loss: 0.4796\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4528 - val_loss: 0.4780\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4530 - val_loss: 0.4768\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4496 - val_loss: 0.4756\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4492 - val_loss: 0.4754\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4474 - val_loss: 0.4735\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4484 - val_loss: 0.4721\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4462 - val_loss: 0.4713\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4453 - val_loss: 0.4701\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4439 - val_loss: 0.4689\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4431 - val_loss: 0.4679\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4422 - val_loss: 0.4671\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4417 - val_loss: 0.4663\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4445 - val_loss: 0.4654\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4400 - val_loss: 0.4645\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4393 - val_loss: 0.4640\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4383 - val_loss: 0.4628\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4375 - val_loss: 0.4619\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4378 - val_loss: 0.4615\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4373 - val_loss: 0.4607\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4357 - val_loss: 0.4595\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4347 - val_loss: 0.4584\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4377 - val_loss: 0.4576\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4338 - val_loss: 0.4569\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4325 - val_loss: 0.4558\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4318 - val_loss: 0.4553\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4313 - val_loss: 0.4542\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4309 - val_loss: 0.4537\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4300 - val_loss: 0.4531\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4311 - val_loss: 0.4521\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4295 - val_loss: 0.4519\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4306 - val_loss: 0.4506\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4276 - val_loss: 0.4502\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4270 - val_loss: 0.4493\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4290 - val_loss: 0.4488\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4263 - val_loss: 0.4479\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4274 - val_loss: 0.4474\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4251 - val_loss: 0.4465\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4245 - val_loss: 0.4463\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4238 - val_loss: 0.4455\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4229 - val_loss: 0.4450\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4232 - val_loss: 0.4443\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.4393\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023818359C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023818359C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "249/291 [========================>.....] - ETA: 0s - loss: 3.5064WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.3167 - val_loss: 2.3793\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 1.7506 - val_loss: 1.4978\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 1.2123 - val_loss: 1.1594\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.9958 - val_loss: 1.0086\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.8925 - val_loss: 0.9306\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.8378 - val_loss: 0.8840\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.8097 - val_loss: 0.8539\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.7802 - val_loss: 0.8318\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.7605 - val_loss: 0.8133\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.7466 - val_loss: 0.7980\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 950us/step - loss: 0.7324 - val_loss: 0.7844\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.7187 - val_loss: 0.7724\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.7074 - val_loss: 0.7611\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.6974 - val_loss: 0.7503\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.6882 - val_loss: 0.7407\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.6792 - val_loss: 0.7312\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.6698 - val_loss: 0.7223\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 946us/step - loss: 0.6628 - val_loss: 0.7140\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.6544 - val_loss: 0.7058\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6490 - val_loss: 0.6978\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.6391 - val_loss: 0.6902\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.6331 - val_loss: 0.6831\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.6271 - val_loss: 0.6761\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.6200 - val_loss: 0.6692\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.6158 - val_loss: 0.6629\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.6079 - val_loss: 0.6568\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.6031 - val_loss: 0.6505\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.5980 - val_loss: 0.6446\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5909 - val_loss: 0.6390\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5866 - val_loss: 0.6334\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.5812 - val_loss: 0.6282\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.5773 - val_loss: 0.6230\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.6178\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.5676 - val_loss: 0.6131\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.5639 - val_loss: 0.6084\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5619 - val_loss: 0.6039\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.5560 - val_loss: 0.5995\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5515 - val_loss: 0.5952\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5479 - val_loss: 0.5909\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.5466 - val_loss: 0.5869\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5418 - val_loss: 0.5829\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5411 - val_loss: 0.5792\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.5335 - val_loss: 0.5755\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5312 - val_loss: 0.5719\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.5290 - val_loss: 0.5686\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5243 - val_loss: 0.5654\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.5243 - val_loss: 0.5620\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5195 - val_loss: 0.5589\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.5171 - val_loss: 0.5558\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5133 - val_loss: 0.5528\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5111 - val_loss: 0.5501\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.5474\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5059 - val_loss: 0.5446\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5047 - val_loss: 0.5420\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5022 - val_loss: 0.5394\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4994 - val_loss: 0.5369\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4983 - val_loss: 0.5344\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4957 - val_loss: 0.5321\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4941 - val_loss: 0.5300\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4914 - val_loss: 0.5276\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4895 - val_loss: 0.5258\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4878 - val_loss: 0.5237\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.5217\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4846 - val_loss: 0.5195\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4828 - val_loss: 0.5179\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.4828 - val_loss: 0.5159\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4799 - val_loss: 0.5142\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.4778 - val_loss: 0.5125\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4766 - val_loss: 0.5106\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.4779 - val_loss: 0.5091\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4741 - val_loss: 0.5075\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4729 - val_loss: 0.5062\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4710 - val_loss: 0.5045\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4696 - val_loss: 0.5029\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4687 - val_loss: 0.5014\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4680 - val_loss: 0.5004\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4669 - val_loss: 0.4990\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4649 - val_loss: 0.4974\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4635 - val_loss: 0.4962\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4639 - val_loss: 0.4948\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4617 - val_loss: 0.4940\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4614 - val_loss: 0.4926\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4604 - val_loss: 0.4913\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4590 - val_loss: 0.4906\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4578 - val_loss: 0.4894\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4580 - val_loss: 0.4879\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 853us/step - loss: 0.4559 - val_loss: 0.4870\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.4549 - val_loss: 0.4857\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 885us/step - loss: 0.4542 - val_loss: 0.4846\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4546 - val_loss: 0.4839\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4519 - val_loss: 0.4829\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4514 - val_loss: 0.4820\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4503 - val_loss: 0.4808\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4492 - val_loss: 0.4799\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4496 - val_loss: 0.4792\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4480 - val_loss: 0.4780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4478 - val_loss: 0.4767\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4477 - val_loss: 0.4760\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4453 - val_loss: 0.4755\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4451 - val_loss: 0.4743\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.4463\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/291 [========================>.....] - ETA: 0s - loss: 3.6636WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819B2BE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819B2BE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.4704 - val_loss: 2.4250\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 1.8073 - val_loss: 1.4591\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 1.1753 - val_loss: 1.0686\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.8987 - val_loss: 0.8997\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.7774 - val_loss: 0.8215\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.7172 - val_loss: 0.7820\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6856 - val_loss: 0.7589\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.6684 - val_loss: 0.7426\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6552 - val_loss: 0.7291\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6416 - val_loss: 0.7174\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6317 - val_loss: 0.7069\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6234 - val_loss: 0.6960\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.6121 - val_loss: 0.6861\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.6045 - val_loss: 0.6764\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5956 - val_loss: 0.6676\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5884 - val_loss: 0.6589\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5861 - val_loss: 0.6513\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5744 - val_loss: 0.6437\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5689 - val_loss: 0.6351\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5620 - val_loss: 0.6282\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5579 - val_loss: 0.6212\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5507 - val_loss: 0.6143\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5506 - val_loss: 0.6079\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.5402 - val_loss: 0.6019\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.5365 - val_loss: 0.5962\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5320 - val_loss: 0.5903\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5282 - val_loss: 0.5851\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5233 - val_loss: 0.5800\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5192 - val_loss: 0.5748\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5143 - val_loss: 0.5698\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5099 - val_loss: 0.5652\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.5068 - val_loss: 0.5614\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5031 - val_loss: 0.5572\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5000 - val_loss: 0.5530\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4970 - val_loss: 0.5490\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.4942 - val_loss: 0.5453\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4915 - val_loss: 0.5420\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4889 - val_loss: 0.5386\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4864 - val_loss: 0.5357\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4863 - val_loss: 0.5327\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4815 - val_loss: 0.5298\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4801 - val_loss: 0.5268\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4774 - val_loss: 0.5240\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4778 - val_loss: 0.5218\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.5192\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4731 - val_loss: 0.5163\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4708 - val_loss: 0.5140\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4681 - val_loss: 0.5119\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.4671 - val_loss: 0.5101\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4653 - val_loss: 0.5081\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4642 - val_loss: 0.5063\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4629 - val_loss: 0.5045\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4603 - val_loss: 0.5023\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4594 - val_loss: 0.5008\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4578 - val_loss: 0.4988\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.4578 - val_loss: 0.4970\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 946us/step - loss: 0.4618 - val_loss: 0.4957\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4555 - val_loss: 0.4941\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4575 - val_loss: 0.4928\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4536 - val_loss: 0.4912\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4514 - val_loss: 0.4897\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4496 - val_loss: 0.4884\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4487 - val_loss: 0.4872\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4480 - val_loss: 0.4858\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4466 - val_loss: 0.4846\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4467 - val_loss: 0.4834\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4454 - val_loss: 0.4824\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4453 - val_loss: 0.4812\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4433 - val_loss: 0.4801\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4423 - val_loss: 0.4791\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4417 - val_loss: 0.4781\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4409 - val_loss: 0.4771\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4395 - val_loss: 0.4760\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4392 - val_loss: 0.4751\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4381 - val_loss: 0.4741\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4384 - val_loss: 0.4731\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4369 - val_loss: 0.4721\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4362 - val_loss: 0.4713\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4357 - val_loss: 0.4706\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4346 - val_loss: 0.4697\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4339 - val_loss: 0.4689\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4351 - val_loss: 0.4680\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4326 - val_loss: 0.4671\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4319 - val_loss: 0.4663\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4319 - val_loss: 0.4655\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4316 - val_loss: 0.4646\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4302 - val_loss: 0.4641\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4299 - val_loss: 0.4631\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4306 - val_loss: 0.4626\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4285 - val_loss: 0.4620\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4290 - val_loss: 0.4615\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.4293 - val_loss: 0.4608\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4266 - val_loss: 0.4599\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4264 - val_loss: 0.4591\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4261 - val_loss: 0.4585\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4273 - val_loss: 0.4578\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4247 - val_loss: 0.4571\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4250 - val_loss: 0.4566\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4237 - val_loss: 0.4558\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4232 - val_loss: 0.4551\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.4472\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BBAC730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BBAC730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "253/291 [=========================>....] - ETA: 0s - loss: 3.1453WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238180D29D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238180D29D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.0079 - val_loss: 2.2778\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 1.7043 - val_loss: 1.4774\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 1.1994 - val_loss: 1.1339\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.9644 - val_loss: 0.9687\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.8487 - val_loss: 0.8853\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.7875 - val_loss: 0.8401\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.7540 - val_loss: 0.8128\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.7320 - val_loss: 0.7950\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.7183 - val_loss: 0.7813\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.7069 - val_loss: 0.7698\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6966 - val_loss: 0.7593\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6877 - val_loss: 0.7495\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6800 - val_loss: 0.7405\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.6723 - val_loss: 0.7314\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.6606 - val_loss: 0.7233\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.6540 - val_loss: 0.7148\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 884us/step - loss: 0.6464 - val_loss: 0.7069\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.6407 - val_loss: 0.6989\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.6321 - val_loss: 0.6916\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.6257 - val_loss: 0.6846\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.6187 - val_loss: 0.6774\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.6151 - val_loss: 0.6705\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.6070 - val_loss: 0.6640\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.6013 - val_loss: 0.6576\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.5979 - val_loss: 0.6515\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5910 - val_loss: 0.6456\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.5886 - val_loss: 0.6397\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5816 - val_loss: 0.6340\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.5768 - val_loss: 0.6287\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.5721 - val_loss: 0.6236\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.5682 - val_loss: 0.6186\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.5638 - val_loss: 0.6139\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5588 - val_loss: 0.6093\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.5541 - val_loss: 0.6046\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5533 - val_loss: 0.6003\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5469 - val_loss: 0.5961\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5441 - val_loss: 0.5919\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5402 - val_loss: 0.5880\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.5375 - val_loss: 0.5843\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5373 - val_loss: 0.5806\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5306 - val_loss: 0.5772\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5284 - val_loss: 0.5737\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5261 - val_loss: 0.5703\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5217 - val_loss: 0.5672\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5640\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.5164 - val_loss: 0.5611\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.5141 - val_loss: 0.5582\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5118 - val_loss: 0.5556\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.5092 - val_loss: 0.5529\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.5073 - val_loss: 0.5503\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5072 - val_loss: 0.5477\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5030 - val_loss: 0.5452\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5016 - val_loss: 0.5429\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4995 - val_loss: 0.5405\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4992 - val_loss: 0.5384\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4953 - val_loss: 0.5363\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4941 - val_loss: 0.5342\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4924 - val_loss: 0.5320\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4894 - val_loss: 0.5303\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4887 - val_loss: 0.5282\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4867 - val_loss: 0.5266\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4850 - val_loss: 0.5248\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4840 - val_loss: 0.5230\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4820 - val_loss: 0.5212\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4810 - val_loss: 0.5199\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4802 - val_loss: 0.5182\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4786 - val_loss: 0.5165\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4772 - val_loss: 0.5150\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4753 - val_loss: 0.5135\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4741 - val_loss: 0.5120\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4733 - val_loss: 0.5106\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4725 - val_loss: 0.5093\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4712 - val_loss: 0.5078\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4708 - val_loss: 0.5066\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4684 - val_loss: 0.5053\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4688 - val_loss: 0.5040\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4665 - val_loss: 0.5027\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4652 - val_loss: 0.5016\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4646 - val_loss: 0.5004\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4631 - val_loss: 0.4992\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4644 - val_loss: 0.4981\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4614 - val_loss: 0.4972\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4608 - val_loss: 0.4960\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4613 - val_loss: 0.4948\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4596 - val_loss: 0.4938\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4580 - val_loss: 0.4929\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4577 - val_loss: 0.4919\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4573 - val_loss: 0.4910\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4576 - val_loss: 0.4898\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4551 - val_loss: 0.4888\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4544 - val_loss: 0.4879\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4535 - val_loss: 0.4871\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4520 - val_loss: 0.4862\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4510 - val_loss: 0.4854\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4511 - val_loss: 0.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4500 - val_loss: 0.4835\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4493 - val_loss: 0.4827\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4488 - val_loss: 0.4819\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4501 - val_loss: 0.4811\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.4478 - val_loss: 0.4802\n",
      "73/73 [==============================] - 0s 588us/step - loss: 0.4674\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816ACCF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816ACCF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "226/291 [======================>.......] - ETA: 0s - loss: 3.6117WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819507B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819507B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.3012 - val_loss: 2.1252\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.5518 - val_loss: 1.2787\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0513 - val_loss: 0.9851\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8536 - val_loss: 0.8596\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7658 - val_loss: 0.7947\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7142 - val_loss: 0.7565\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7004 - val_loss: 0.7322\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 0.7107\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6520 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6361 - val_loss: 0.6806\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6254 - val_loss: 0.6680\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6571\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.6058 - val_loss: 0.6466\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5970 - val_loss: 0.6379\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5917 - val_loss: 0.6288\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.6202\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5780 - val_loss: 0.6126\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.6052\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5614 - val_loss: 0.5983\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5917\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5503 - val_loss: 0.5856\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.5450 - val_loss: 0.5793\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.5394 - val_loss: 0.5745\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5687\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5635\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5269 - val_loss: 0.5592\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5546\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5503\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.5458\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5138 - val_loss: 0.5415\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.5383\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.5340\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5309\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5275\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4964 - val_loss: 0.5239\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 991us/step - loss: 0.4928 - val_loss: 0.5209\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4909 - val_loss: 0.5185\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4887 - val_loss: 0.5153\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.5127\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4828 - val_loss: 0.5104\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.5075\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4786 - val_loss: 0.5053\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.5031\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4752 - val_loss: 0.5001\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4736 - val_loss: 0.4977\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4952\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4686 - val_loss: 0.4932\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4919\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4890\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.4867\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4853\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4836\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4815\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4794\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4777\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4744\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4731\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4489 - val_loss: 0.4709\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4702\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4468 - val_loss: 0.4682\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.4664\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4651\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.4632\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4617\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4611\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4395 - val_loss: 0.4600\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 0.4579\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4562\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4553\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4332 - val_loss: 0.4535\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4328 - val_loss: 0.4525\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4517\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.4351 - val_loss: 0.4495\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4310 - val_loss: 0.4482\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4474\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4284 - val_loss: 0.4462\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4452\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4436\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4428\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4419\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4401\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4391\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4378\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4368\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4358\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4347\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4341\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4326\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4320\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4322\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4299\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4289\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4286\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4269\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4263\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4251\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4247\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4238\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4226\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3759\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BA5E488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BA5E488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "225/291 [======================>.......] - ETA: 0s - loss: 4.7090WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818308048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818308048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 4.2584 - val_loss: 2.5719\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.7319 - val_loss: 1.3514\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0773 - val_loss: 1.0018\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8737 - val_loss: 0.8815\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7903 - val_loss: 0.8267\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7488 - val_loss: 0.7943\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7215 - val_loss: 0.7720\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7051 - val_loss: 0.7542\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6878 - val_loss: 0.7398\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6753 - val_loss: 0.7263\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6621 - val_loss: 0.7141\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6521 - val_loss: 0.7031\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6415 - val_loss: 0.6928\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6341 - val_loss: 0.6828\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6226 - val_loss: 0.6738\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6642\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6555\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6477\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5894 - val_loss: 0.6396\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 0.6314\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.6238\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.6164\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5658 - val_loss: 0.6097\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 998us/step - loss: 0.5563 - val_loss: 0.6036\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.5968\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.5448 - val_loss: 0.5908\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5414 - val_loss: 0.5850\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5797\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5740\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.5684\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5640\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.5587\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.5543\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5504\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.5042 - val_loss: 0.5456\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 0.5411\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4953 - val_loss: 0.5378\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4910 - val_loss: 0.5335\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4872 - val_loss: 0.5294\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4836 - val_loss: 0.5264\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 0.5217\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4773 - val_loss: 0.5176\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.5137\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4714 - val_loss: 0.5107\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4681 - val_loss: 0.5074\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.5049\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.5013\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4604 - val_loss: 0.4985\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4972\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4941\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4527 - val_loss: 0.4912\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4887\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4877\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4839\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4811\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4790\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4772\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4757\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4378 - val_loss: 0.4724\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4708\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4681\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4668\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4646\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4631\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4634\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4620\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4596\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4579\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4556\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4538\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4532\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4527\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4171 - val_loss: 0.4506\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4490\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4487\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4140 - val_loss: 0.4470\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4468\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4447\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4442\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4424\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4404\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4400\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4386\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4379\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.4367\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4050 - val_loss: 0.4354\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.4341\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4337\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4022 - val_loss: 0.4336\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4320\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.4307\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4311\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4298\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4278\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4278\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4258\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4250\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4243\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4237\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4240\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.4086\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CEE2BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CEE2BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "288/291 [============================>.] - ETA: 0s - loss: 2.6733WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238180D2378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238180D2378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.6568 - val_loss: 1.6089\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.1790 - val_loss: 0.9729\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8390 - val_loss: 0.8275\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7452 - val_loss: 0.7794\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7095 - val_loss: 0.7551\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6894 - val_loss: 0.7379\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6757 - val_loss: 0.7239\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6645 - val_loss: 0.7108\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6490 - val_loss: 0.6981\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6374 - val_loss: 0.6868\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6273 - val_loss: 0.6766\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6661\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6564\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5990 - val_loss: 0.6470\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5913 - val_loss: 0.6379\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.6298\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5759 - val_loss: 0.6219\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.6143\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 0.6071\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5557 - val_loss: 0.6004\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.5529 - val_loss: 0.5936\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5874\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.5813\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5336 - val_loss: 0.5758\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5703\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5649\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.5601\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5145 - val_loss: 0.5552\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5505\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5462\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5032 - val_loss: 0.5421\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4979 - val_loss: 0.5383\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4947 - val_loss: 0.5344\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4911 - val_loss: 0.5307\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.5271\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.5234\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4835 - val_loss: 0.5202\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.5169\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.5140\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.5111\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4725 - val_loss: 0.5080\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.5052\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4677 - val_loss: 0.5028\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.5003\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4977\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4951\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4928\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4572 - val_loss: 0.4906\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4884\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4860\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4842\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4504 - val_loss: 0.4823\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.4481 - val_loss: 0.4801\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4785\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4765\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4748\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4727\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4710\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4692\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4372 - val_loss: 0.4676\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4369 - val_loss: 0.4663\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4646\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4630\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4614\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4604\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4301 - val_loss: 0.4586\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4570\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4282 - val_loss: 0.4557\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4265 - val_loss: 0.4543\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4530\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4517\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4226 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4491\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4210 - val_loss: 0.4477\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4466\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4185 - val_loss: 0.4453\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4441\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4171 - val_loss: 0.4427\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4417\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4405\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4394\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4126 - val_loss: 0.4384\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4121 - val_loss: 0.4373\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4105 - val_loss: 0.4363\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4353\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4342\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4335\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4324\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4309\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4057 - val_loss: 0.4301\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4293\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4283\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4275\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4267\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4256\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4249\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4240\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.4231\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4221\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4213\n",
      "73/73 [==============================] - 0s 588us/step - loss: 0.4015\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BAA1158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BAA1158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "219/291 [=====================>........] - ETA: 0s - loss: 3.4794WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CFA8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CFA8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.1265 - val_loss: 2.0034\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4757 - val_loss: 1.2271\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0280 - val_loss: 0.9590\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8522 - val_loss: 0.8429\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7666 - val_loss: 0.7893\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7185 - val_loss: 0.7617\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6946 - val_loss: 0.7452\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6745 - val_loss: 0.7315\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6579 - val_loss: 0.7195\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6445 - val_loss: 0.7086\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6330 - val_loss: 0.6970\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6868\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.6759\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6660\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5949 - val_loss: 0.6561\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 0.6468\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5791 - val_loss: 0.6382\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 0.6294\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5641 - val_loss: 0.6220\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5579 - val_loss: 0.6145\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.6069\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5457 - val_loss: 0.5994\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5929\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.5860\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5794\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 0.5731\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5676\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5143 - val_loss: 0.5618\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.5563\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5511\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 0.5457\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4982 - val_loss: 0.5412\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4929 - val_loss: 0.5362\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5319\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4861 - val_loss: 0.5277\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.5234\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4790 - val_loss: 0.5196\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.5160\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4723 - val_loss: 0.5123\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.5089\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.5056\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.5024\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4990\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.4963\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4937\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4543 - val_loss: 0.4907\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4882\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4855\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4832\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.4809\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4786\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4764\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4742\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4721\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4702\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4681\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4663\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4651\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4627\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4611\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4595\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4578\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4563\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 991us/step - loss: 0.4236 - val_loss: 0.4546\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4532\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.4522\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4508\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4493\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4482\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4468\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4454\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4444\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4434\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4419\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4406\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4398\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.4390\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4377\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4367\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4355\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4343\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.4334\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4324\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4316\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4306\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4296\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4293\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4279\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4272\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4264\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.3965 - val_loss: 0.4255\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4250\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4238\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4230\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4220\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4213\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4205\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4198\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4194\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4187\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.4142\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381979E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381979E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "226/291 [======================>.......] - ETA: 0s - loss: 3.6372WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198CE730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198CE730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.2937 - val_loss: 2.1015\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 1.5667 - val_loss: 1.3055\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0630 - val_loss: 0.9975\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8525 - val_loss: 0.8581\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7512 - val_loss: 0.7899\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7034 - val_loss: 0.7529\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.6759 - val_loss: 0.7301\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6572 - val_loss: 0.7132\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.6993\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 0.6867\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6258 - val_loss: 0.6751\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6642\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6027 - val_loss: 0.6540\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5921 - val_loss: 0.6444\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 0.6352\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5770 - val_loss: 0.6271\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5694 - val_loss: 0.6191\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5616 - val_loss: 0.6117\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.6044\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5974\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5433 - val_loss: 0.5915\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.5848\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.5786\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5321 - val_loss: 0.5729\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.5677\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.5623\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5574\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5526\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5042 - val_loss: 0.5481\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.5437\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4968 - val_loss: 0.5392\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4933 - val_loss: 0.5351\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.5312\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4860 - val_loss: 0.5275\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4828 - val_loss: 0.5246\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.5207\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4770 - val_loss: 0.5172\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.5143\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.5108\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4686 - val_loss: 0.5080\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4655 - val_loss: 0.5056\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.5025\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4998\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4611 - val_loss: 0.4971\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4947\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4921\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4898\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4877\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4854\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4490 - val_loss: 0.4828\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4442 - val_loss: 0.4810\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4791\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4769\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4749\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.4731\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4711\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4694\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4677\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4661\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.4644\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4627\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4611\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4594\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4578\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.421 - 0s 997us/step - loss: 0.4228 - val_loss: 0.4564\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4548\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4532\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4193 - val_loss: 0.4517\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4503\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4491\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4171 - val_loss: 0.4478\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4465\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4452\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4438\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4428\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4413\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4405\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4393\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4382\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4368\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4358\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4349\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4338\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4324\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4015 - val_loss: 0.4314\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4307\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4302\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4286\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4275\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4269\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.3952 - val_loss: 0.4257\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4253\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.3934 - val_loss: 0.4238\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.4228\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4221\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4216\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4202\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 991us/step - loss: 0.3943 - val_loss: 0.4196\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4188\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.3880 - val_loss: 0.4183\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.4163\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B97840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/291 [========================>.....] - ETA: 0s - loss: 1.1796WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238196BD488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3344 - val_loss: 0.8219\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.6252 - val_loss: 0.6136\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5446 - val_loss: 0.5560\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5100 - val_loss: 0.5201\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4882 - val_loss: 0.5024\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4690 - val_loss: 0.4831\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4587 - val_loss: 0.4728\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4524 - val_loss: 0.4591\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4391 - val_loss: 0.4578\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4343 - val_loss: 0.4624\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 926us/step - loss: 0.4338 - val_loss: 0.4429\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4281 - val_loss: 0.4358\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4287 - val_loss: 0.4369\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4244 - val_loss: 0.4333\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4254 - val_loss: 0.4428\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4370\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4217 - val_loss: 0.4406\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4218 - val_loss: 0.4273\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4182 - val_loss: 0.4266\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4219 - val_loss: 0.4264\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 942us/step - loss: 0.4168 - val_loss: 0.4281\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4172 - val_loss: 0.4339\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4171 - val_loss: 0.4297\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4162 - val_loss: 0.4268\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4160 - val_loss: 0.4245\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4159 - val_loss: 0.4282\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4177 - val_loss: 0.4291\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4147 - val_loss: 0.4262\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4142 - val_loss: 0.4204\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4147 - val_loss: 0.4210\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4154 - val_loss: 0.4260\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4142 - val_loss: 0.4211\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4156 - val_loss: 0.4270\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.3871\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816D08AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023816D08AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "266/291 [==========================>...] - ETA: 0s - loss: 1.5819WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A0B8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A0B8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.5081 - val_loss: 0.7544\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.6619 - val_loss: 0.6734\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.6030 - val_loss: 0.6300\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5572 - val_loss: 0.5889\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.5186 - val_loss: 0.5405\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4918 - val_loss: 0.5147\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4738 - val_loss: 0.5330\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4620 - val_loss: 0.4828\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4530 - val_loss: 0.4747\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.4428 - val_loss: 0.4672\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4477 - val_loss: 0.4581\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4428 - val_loss: 0.4558\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.4331 - val_loss: 0.4658\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4273 - val_loss: 0.4397\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4287 - val_loss: 0.4550\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4249 - val_loss: 0.4413\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4301 - val_loss: 0.4402\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4225 - val_loss: 0.4402\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4191 - val_loss: 0.4247\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4139 - val_loss: 0.4219\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4132 - val_loss: 0.4223\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4192 - val_loss: 0.4333\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4156 - val_loss: 0.4227\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4111 - val_loss: 0.4353\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4083 - val_loss: 0.4130\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4069 - val_loss: 0.4126\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4054 - val_loss: 0.4111\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4058 - val_loss: 0.4116\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 850us/step - loss: 0.4034 - val_loss: 0.4101\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4016 - val_loss: 0.4068\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4011 - val_loss: 0.4071\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4000 - val_loss: 0.4096\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3988 - val_loss: 0.4078\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3987 - val_loss: 0.4084\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3964 - val_loss: 0.4044\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3953 - val_loss: 0.4047\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3966 - val_loss: 0.4042\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3939 - val_loss: 0.3995\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3989 - val_loss: 0.4120\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.3955 - val_loss: 0.4115\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3948 - val_loss: 0.3996\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3982 - val_loss: 0.4066\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3941 - val_loss: 0.4017\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 853us/step - loss: 0.3920 - val_loss: 0.4006\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3926 - val_loss: 0.4050\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3912 - val_loss: 0.3972\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3947 - val_loss: 0.4016\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 918us/step - loss: 0.3950 - val_loss: 0.4026\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3901 - val_loss: 0.3968\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3905 - val_loss: 0.3965\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3919 - val_loss: 0.4101\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3906 - val_loss: 0.3975\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3893 - val_loss: 0.3963\n",
      "73/73 [==============================] - 0s 506us/step - loss: 0.3831\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023817FFAAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023817FFAAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "267/291 [==========================>...] - ETA: 0s - loss: 2.2524WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE27B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE27B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.1665 - val_loss: 1.4705\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 1.1640 - val_loss: 0.8888\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.7274 - val_loss: 0.6829\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.6274 - val_loss: 0.6234\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.5805 - val_loss: 0.5833\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.5441 - val_loss: 0.5538\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5131 - val_loss: 0.5282\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4870 - val_loss: 0.5065\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4725 - val_loss: 0.4949\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4650 - val_loss: 0.4867\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4599 - val_loss: 0.4848\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4530 - val_loss: 0.4848\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4522 - val_loss: 0.4783\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4493 - val_loss: 0.4872\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4433 - val_loss: 0.4654\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4457 - val_loss: 0.4613\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4395 - val_loss: 0.4641\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4362 - val_loss: 0.4565\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4369 - val_loss: 0.4614\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4377 - val_loss: 0.4519\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4303 - val_loss: 0.4596\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4277 - val_loss: 0.4571\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4249 - val_loss: 0.4793\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4341\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4187 - val_loss: 0.4531\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4179 - val_loss: 0.4519\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4150 - val_loss: 0.4320\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4108 - val_loss: 0.4306\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4189 - val_loss: 0.4487\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4289 - val_loss: 0.4263\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4117 - val_loss: 0.4406\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4141 - val_loss: 0.4179\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4069 - val_loss: 0.4289\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4012 - val_loss: 0.4303\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4058 - val_loss: 0.4329\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3991 - val_loss: 0.4247\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3984 - val_loss: 0.4272\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3981 - val_loss: 0.4264\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3949 - val_loss: 0.4112\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3942 - val_loss: 0.4236\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4127 - val_loss: 0.4095\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3927 - val_loss: 0.4000\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.3886 - val_loss: 0.4166\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3973 - val_loss: 0.4163\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3972 - val_loss: 0.4019\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3898 - val_loss: 0.4070\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3887 - val_loss: 0.4191\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3865 - val_loss: 0.4268\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4143 - val_loss: 0.4065\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3851 - val_loss: 0.3996\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3875 - val_loss: 0.4210\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3944 - val_loss: 0.3979\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3917 - val_loss: 0.3921\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3838 - val_loss: 0.3974\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 915us/step - loss: 0.3823 - val_loss: 0.4035\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3893 - val_loss: 0.4136\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3833 - val_loss: 0.3897\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3801 - val_loss: 0.3911\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3831 - val_loss: 0.4051\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3833 - val_loss: 0.3885\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3802 - val_loss: 0.3885\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.3784 - val_loss: 0.3904\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3787 - val_loss: 0.3912\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3780 - val_loss: 0.4169\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3848 - val_loss: 0.3917\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3764 - val_loss: 0.3878\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3791 - val_loss: 0.3867\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3758 - val_loss: 0.3970\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3847 - val_loss: 0.3904\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3802 - val_loss: 0.4001\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3829 - val_loss: 0.3929\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4191 - val_loss: 0.4037\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3913\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381A4C51E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381A4C51E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "257/291 [=========================>....] - ETA: 0s - loss: 1.7236WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B9FB400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.6363 - val_loss: 0.9103\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.7552 - val_loss: 0.7243\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.6486 - val_loss: 0.6606\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5814 - val_loss: 0.6045\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.5374 - val_loss: 0.5672\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5029 - val_loss: 0.5334\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4787 - val_loss: 0.5104\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4584 - val_loss: 0.4886\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4436 - val_loss: 0.4733\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4329 - val_loss: 0.4615\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4257 - val_loss: 0.4519\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4193 - val_loss: 0.4456\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4158 - val_loss: 0.4407\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4100 - val_loss: 0.4375\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4080 - val_loss: 0.4339\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4093 - val_loss: 0.4307\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4019 - val_loss: 0.4277\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3990 - val_loss: 0.4259\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3994 - val_loss: 0.4228\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3961 - val_loss: 0.4194\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3944 - val_loss: 0.4191\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3943 - val_loss: 0.4180\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3929 - val_loss: 0.4151\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3911 - val_loss: 0.4150\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.3903 - val_loss: 0.4149\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3891 - val_loss: 0.4147\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3877 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3871 - val_loss: 0.4101\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3863 - val_loss: 0.4111\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3861 - val_loss: 0.4111\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3879 - val_loss: 0.4106\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3859 - val_loss: 0.4082\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3840 - val_loss: 0.4114\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3848 - val_loss: 0.4064\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3820 - val_loss: 0.4085\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3821 - val_loss: 0.4080\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3807 - val_loss: 0.4062\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3807 - val_loss: 0.4045\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3804 - val_loss: 0.4026\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3792 - val_loss: 0.4059\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3792 - val_loss: 0.4041\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3795 - val_loss: 0.4010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 533us/step - loss: 0.4025\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195E9048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195E9048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "266/291 [==========================>...] - ETA: 0s - loss: 1.5545WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CF71AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CF71AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4907 - val_loss: 0.7527\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.6523 - val_loss: 0.6785\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.5987 - val_loss: 0.6325\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5888\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5295 - val_loss: 0.5574\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5039 - val_loss: 0.5350\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4893 - val_loss: 0.5141\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4759 - val_loss: 0.5106\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4655 - val_loss: 0.4894\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4555 - val_loss: 0.4811\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4476 - val_loss: 0.4736\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4430 - val_loss: 0.4674\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4372 - val_loss: 0.4639\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4325 - val_loss: 0.4529\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4265 - val_loss: 0.4532\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4226 - val_loss: 0.4429\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4175 - val_loss: 0.4363\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4136 - val_loss: 0.4292\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4107 - val_loss: 0.4274\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4085 - val_loss: 0.4245\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4060 - val_loss: 0.4233\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4044 - val_loss: 0.4214\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4020 - val_loss: 0.4202\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4016 - val_loss: 0.4213\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.3998 - val_loss: 0.4237\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4000 - val_loss: 0.4130\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3980 - val_loss: 0.4111\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3976 - val_loss: 0.4151\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 864us/step - loss: 0.3972 - val_loss: 0.4155\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3963 - val_loss: 0.4116\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3960 - val_loss: 0.4101\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.3948 - val_loss: 0.4112\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3926 - val_loss: 0.4059\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.3929 - val_loss: 0.4088\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3927 - val_loss: 0.4108\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3912 - val_loss: 0.4082\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 874us/step - loss: 0.3917 - val_loss: 0.4077\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3986 - val_loss: 0.4045\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3903 - val_loss: 0.4109\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3887 - val_loss: 0.4041\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3879 - val_loss: 0.4040\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.4053\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195E9EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238195E9EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.8240WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B820400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B820400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8211 - val_loss: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4539\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4111\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4369\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3824\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3731\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3665\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3571\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.3558\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3686\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3531\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3395\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3628\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3366\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3512\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3856\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.4246\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3309\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3226\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3218\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3156\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3281\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.3221\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3233\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.3107\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3862\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3373\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.3634\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3070\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.3125\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3217\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.3082\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.3675\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.3274\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.3149\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3199\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3223\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.3169\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.2984\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2732 - val_loss: 0.3436\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.2968\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.3096\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3042\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3018\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3251\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2708 - val_loss: 0.3038\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2691 - val_loss: 0.3070\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2676 - val_loss: 0.2920\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3806\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.2921\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2663 - val_loss: 0.3093\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.2942\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2642 - val_loss: 0.3789\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.3175\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.2966\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819507048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819507048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "289/291 [============================>.] - ETA: 0s - loss: 0.8897WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023817FFA730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023817FFA730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.8857 - val_loss: 0.5397\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4582\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4326\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.4384\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.4081\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3970\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4255\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3667\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3620\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3594\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.4344\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.3621\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3548\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3671\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3600\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3412\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3525\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3489\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3378\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3396\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3360\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3298\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3238\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3165\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3218\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.3208\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.3561\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3599\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3172\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.3201\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3324\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.3077\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3135\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3290\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.3045\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.4045\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.3201\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3056\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2758 - val_loss: 0.3362\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.3047\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2747 - val_loss: 0.3425\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.3107\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2748 - val_loss: 0.3462\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3565\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3235\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.3393\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2713 - val_loss: 0.3106\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2676 - val_loss: 0.3439\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.3325\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2657 - val_loss: 0.3068\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.2944\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238180D2D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238180D2D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "284/291 [============================>.] - ETA: 0s - loss: 1.0021WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819AB5730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819AB5730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9966 - val_loss: 0.6307\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.4904\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4341\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4417\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3856\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3835\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3696\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.4931\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3925\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3533\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3458\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3490\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3451\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3387\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3207 - val_loss: 0.3612\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3493\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3475\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3484\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3268\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3314\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3161\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.3264\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3358\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.3302\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3081\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3271\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.3143\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.3129\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.3194\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.3190\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3308\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.3516\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3086\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 0.3216\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3566\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2743 - val_loss: 0.3564\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3618\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819959C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819959C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "283/291 [============================>.] - ETA: 0s - loss: 0.9777WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381D21B9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381D21B9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9617 - val_loss: 0.6775\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.7384 - val_loss: 0.9399\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4882 - val_loss: 0.4570\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4215\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.4053\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4050\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.4199\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3900\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3923\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3680\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3679\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3684\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3687\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3808\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3548\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3934\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3511\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3806\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3366\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3394\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3448\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3385\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3703\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3389\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3237\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3342\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.3396\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.3174\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3624\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.4489\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3257\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3276\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3346\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2893 - val_loss: 0.3392\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 0.3178\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.3120\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.3253\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3291\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.3536\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.3166\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3175\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3084\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.3325\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.3300\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2775 - val_loss: 0.3306\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2763 - val_loss: 0.3053\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.3048\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2720 - val_loss: 0.3806\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2731 - val_loss: 0.3717\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2720 - val_loss: 0.3270\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3072\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.2941\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198CE2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198CE2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "274/291 [===========================>..] - ETA: 0s - loss: 1.0544WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0230 - val_loss: 0.5952\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4987 - val_loss: 0.4844\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4497\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.4150\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.3859\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3735\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3699\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3642\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3612\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3720\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.4636\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3468\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3462\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3419\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3435\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3462\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3758\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3304\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3340\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3426\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3314\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3223\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3274\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3276\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3371\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.3234\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3128\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.3125\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3131\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3165\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.3192\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.3083\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.3437\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3216\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.3220\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.3053\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2722 - val_loss: 0.3029\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2696 - val_loss: 0.3037\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3084\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.2990\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3141\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.2996\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.3055\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2629 - val_loss: 0.2936\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.2971\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.3008\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2643 - val_loss: 0.5176\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.2970\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2605 - val_loss: 0.2928\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2583 - val_loss: 0.2958\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2595 - val_loss: 0.2979\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3673\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.3064\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.2920\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2553 - val_loss: 0.3002\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.3125\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198D9158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238198D9158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "241/291 [=======================>......] - ETA: 0s - loss: 1.7008WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE21E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE21E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 1.6117 - val_loss: 1.0711\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.8185 - val_loss: 0.8207\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 926us/step - loss: 0.7176 - val_loss: 0.7501\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.6727 - val_loss: 0.7032\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.6394 - val_loss: 0.6679\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.6187 - val_loss: 0.6404\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5915 - val_loss: 0.6145\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5686 - val_loss: 0.6100\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.5513 - val_loss: 0.5865\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.5351 - val_loss: 0.5600\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5229 - val_loss: 0.5654\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.5113 - val_loss: 0.5378\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.5041 - val_loss: 0.5281\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4964 - val_loss: 0.5178\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4903 - val_loss: 0.5121\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4843 - val_loss: 0.5086\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.4772 - val_loss: 0.4988\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4760 - val_loss: 0.4950\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4699 - val_loss: 0.5042\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.4661 - val_loss: 0.4952\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4632 - val_loss: 0.4834\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.4611 - val_loss: 0.4817\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.4766\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4668 - val_loss: 0.4733\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4535 - val_loss: 0.4787\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4508 - val_loss: 0.4684\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4496 - val_loss: 0.4679\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.4482 - val_loss: 0.4643\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4455 - val_loss: 0.4624\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4432 - val_loss: 0.4612\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4426 - val_loss: 0.4624\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4400 - val_loss: 0.4622\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4381 - val_loss: 0.4558\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4362 - val_loss: 0.4525\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.4367 - val_loss: 0.4594\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4348 - val_loss: 0.4564\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4327 - val_loss: 0.4496\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4312 - val_loss: 0.4487\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4294 - val_loss: 0.4582\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4283 - val_loss: 0.4444\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4269 - val_loss: 0.4432\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4256 - val_loss: 0.4423\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.4250 - val_loss: 0.4420\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4246 - val_loss: 0.4449\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4230 - val_loss: 0.4379\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4223 - val_loss: 0.4358\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4207 - val_loss: 0.4347\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.4187 - val_loss: 0.4334\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.4198 - val_loss: 0.4341\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4164 - val_loss: 0.4331\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4299\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.4308\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4286\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4138 - val_loss: 0.4308\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4114 - val_loss: 0.4263\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4109 - val_loss: 0.4266\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4110 - val_loss: 0.4245\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4259\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4082 - val_loss: 0.4221\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 963us/step - loss: 0.4089 - val_loss: 0.4231\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4065 - val_loss: 0.4213\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4056 - val_loss: 0.4239\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4058 - val_loss: 0.4204\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4046 - val_loss: 0.4216\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4046 - val_loss: 0.4326\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4029 - val_loss: 0.4191\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4018 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4031 - val_loss: 0.4156\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4020 - val_loss: 0.4142\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3996 - val_loss: 0.4130\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4005 - val_loss: 0.4122\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3993 - val_loss: 0.4107\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 870us/step - loss: 0.3979 - val_loss: 0.4103\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.3979 - val_loss: 0.4099\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3961 - val_loss: 0.4095\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3973 - val_loss: 0.4087\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3953 - val_loss: 0.4091\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.3951 - val_loss: 0.4072\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3938 - val_loss: 0.4072\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3931 - val_loss: 0.4054\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3945 - val_loss: 0.4054\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3923 - val_loss: 0.4051\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 894us/step - loss: 0.3915 - val_loss: 0.4036\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3911 - val_loss: 0.4031\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3907 - val_loss: 0.4020\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.3928 - val_loss: 0.4018\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3918 - val_loss: 0.4020\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.3890 - val_loss: 0.4013\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.3888 - val_loss: 0.4003\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3891 - val_loss: 0.3999\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.3876 - val_loss: 0.3993\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3881 - val_loss: 0.3987\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3907 - val_loss: 0.3996\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3871 - val_loss: 0.3984\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3868 - val_loss: 0.3976\n",
      "73/73 [==============================] - 0s 574us/step - loss: 0.3692\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381D21B510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381D21B510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "251/291 [========================>.....] - ETA: 0s - loss: 2.2486WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818359D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023818359D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.1023 - val_loss: 1.2411\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.9379 - val_loss: 0.8951\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.7936 - val_loss: 0.8299\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.7470 - val_loss: 0.7876\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.7124 - val_loss: 0.7547\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6838 - val_loss: 0.7262\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.6607 - val_loss: 0.7000\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.6437 - val_loss: 0.6778\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.6186 - val_loss: 0.6564\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.5994 - val_loss: 0.6379\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.5847 - val_loss: 0.6197\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.5699 - val_loss: 0.6035\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5533 - val_loss: 0.5886\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5401 - val_loss: 0.5753\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.5297 - val_loss: 0.5620\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5217 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.5403\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5038 - val_loss: 0.5318\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4975 - val_loss: 0.5280\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4929 - val_loss: 0.5171\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4856 - val_loss: 0.5117\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4811 - val_loss: 0.5089\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4768 - val_loss: 0.5037\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4730 - val_loss: 0.4991\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 922us/step - loss: 0.4679 - val_loss: 0.4946\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 902us/step - loss: 0.4644 - val_loss: 0.4948\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4620 - val_loss: 0.4870\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4595 - val_loss: 0.4862\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.4558 - val_loss: 0.4871\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4547 - val_loss: 0.4806\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4532 - val_loss: 0.4773\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4493 - val_loss: 0.4733\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4476 - val_loss: 0.4711\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4451 - val_loss: 0.4680\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4444 - val_loss: 0.4688\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4436 - val_loss: 0.4653\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4401 - val_loss: 0.4633\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4396 - val_loss: 0.4603\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4368 - val_loss: 0.4659\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4356 - val_loss: 0.4558\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 877us/step - loss: 0.4348 - val_loss: 0.4555\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4328 - val_loss: 0.4537\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4322 - val_loss: 0.4530\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4299 - val_loss: 0.4528\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4294 - val_loss: 0.4502\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4282 - val_loss: 0.4480\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 860us/step - loss: 0.4275 - val_loss: 0.4484\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4259 - val_loss: 0.4469\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4244 - val_loss: 0.4458\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4251 - val_loss: 0.4440\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4215 - val_loss: 0.4397\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.4216 - val_loss: 0.4387\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4198 - val_loss: 0.4377\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4173 - val_loss: 0.4362\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4167 - val_loss: 0.4349\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4353\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4143 - val_loss: 0.4322\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.4157 - val_loss: 0.4384\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4154 - val_loss: 0.4307\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4141 - val_loss: 0.4297\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4339\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4267\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4315\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4304\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.4073 - val_loss: 0.4243\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4077 - val_loss: 0.4235\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4241\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4067 - val_loss: 0.4228\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4070 - val_loss: 0.4236\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4042 - val_loss: 0.4217\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4044 - val_loss: 0.4202\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.4033 - val_loss: 0.4186\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.4027 - val_loss: 0.4196\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4026 - val_loss: 0.4189\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.4001 - val_loss: 0.4178\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4009 - val_loss: 0.4180\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.3995 - val_loss: 0.4171\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.4030\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381986E400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "259/291 [=========================>....] - ETA: 0s - loss: 1.9404WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEC4400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEC4400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.8270 - val_loss: 1.0233\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.8120 - val_loss: 0.8167\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 857us/step - loss: 0.7151 - val_loss: 0.7538\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6743 - val_loss: 0.7140\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.6408 - val_loss: 0.6851\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.6161 - val_loss: 0.6607\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.5977 - val_loss: 0.6393\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 942us/step - loss: 0.5790 - val_loss: 0.6202\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5631 - val_loss: 0.6036\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.5514 - val_loss: 0.5890\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.5356 - val_loss: 0.5755\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5653\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.5155 - val_loss: 0.5538\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.5092 - val_loss: 0.5454\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.5014 - val_loss: 0.5358\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.5286\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4868 - val_loss: 0.5213\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.5150\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4753 - val_loss: 0.5102\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.5041\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.4683 - val_loss: 0.4995\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4630 - val_loss: 0.4943\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4597 - val_loss: 0.4915\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 871us/step - loss: 0.4563 - val_loss: 0.4856\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 943us/step - loss: 0.4544 - val_loss: 0.4846\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 853us/step - loss: 0.4506 - val_loss: 0.4785\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4472 - val_loss: 0.4772\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4725\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4698\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4675\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4366 - val_loss: 0.4657\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4355 - val_loss: 0.4615\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4323 - val_loss: 0.4600\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4325 - val_loss: 0.4570\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.4300 - val_loss: 0.4544\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4527\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4510\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.4238 - val_loss: 0.4485\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4218 - val_loss: 0.4464\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4207 - val_loss: 0.4446\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.4432\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4413\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.4184 - val_loss: 0.4394\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4171 - val_loss: 0.4376\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 853us/step - loss: 0.4138 - val_loss: 0.4363\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4134 - val_loss: 0.4351\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.4113 - val_loss: 0.4349\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4326\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.4086 - val_loss: 0.4306\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4088 - val_loss: 0.4297\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 843us/step - loss: 0.4062 - val_loss: 0.4293\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.4071 - val_loss: 0.4272\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 867us/step - loss: 0.4047 - val_loss: 0.4255\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 884us/step - loss: 0.4034 - val_loss: 0.4255\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4241\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4230\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4006 - val_loss: 0.4219\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4003 - val_loss: 0.4202\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4203\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.3978 - val_loss: 0.4190\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3969 - val_loss: 0.4176\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3960 - val_loss: 0.4171\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3958 - val_loss: 0.4163\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3946 - val_loss: 0.4149\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.3944 - val_loss: 0.4143\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.3925 - val_loss: 0.4133\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3935 - val_loss: 0.4124\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3908 - val_loss: 0.4123\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3917 - val_loss: 0.4108\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.3902 - val_loss: 0.4099\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3913 - val_loss: 0.4095\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3889 - val_loss: 0.4087\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.3876 - val_loss: 0.4083\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4071\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4067\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 918us/step - loss: 0.3874 - val_loss: 0.4062\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3858 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 881us/step - loss: 0.3858 - val_loss: 0.4046\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 836us/step - loss: 0.3840 - val_loss: 0.4041\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 898us/step - loss: 0.3854 - val_loss: 0.4028\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.3825 - val_loss: 0.4022\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3821 - val_loss: 0.4028\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 850us/step - loss: 0.3815 - val_loss: 0.4008\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.3815 - val_loss: 0.4010\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.3808 - val_loss: 0.4003\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.3794 - val_loss: 0.3987\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 956us/step - loss: 0.3799 - val_loss: 0.3994\n",
      "73/73 [==============================] - 0s 643us/step - loss: 0.3795\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B9FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B9FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "257/291 [=========================>....] - ETA: 0s - loss: 2.8064WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A54268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A54268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.6151 - val_loss: 1.3002\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.9864 - val_loss: 0.9000\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.7813 - val_loss: 0.8116\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 991us/step - loss: 0.7194 - val_loss: 0.7697\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6839 - val_loss: 0.7397\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.6589 - val_loss: 0.7144\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 891us/step - loss: 0.6315 - val_loss: 0.6899\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 922us/step - loss: 0.6133 - val_loss: 0.6695\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.5966 - val_loss: 0.6518\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.5841 - val_loss: 0.6362\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.5666 - val_loss: 0.6207\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.5546 - val_loss: 0.6076\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5438 - val_loss: 0.5964\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.5345 - val_loss: 0.5848\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.5261 - val_loss: 0.5749\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.5195 - val_loss: 0.5656\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5103 - val_loss: 0.5565\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.5037 - val_loss: 0.5480\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4995 - val_loss: 0.5422\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.5358\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4895 - val_loss: 0.5307\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4837 - val_loss: 0.5245\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.5210\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4767 - val_loss: 0.5167\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4725 - val_loss: 0.5119\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4734 - val_loss: 0.5078\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.5044\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.5010\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4604 - val_loss: 0.4983\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.4937\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4564 - val_loss: 0.4908\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4526 - val_loss: 0.4876\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4511 - val_loss: 0.4855\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.4480 - val_loss: 0.4831\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4458 - val_loss: 0.4795\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4446 - val_loss: 0.4776\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4746\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 998us/step - loss: 0.4409 - val_loss: 0.4725\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.4376 - val_loss: 0.4708\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4361 - val_loss: 0.4675\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.4659\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4320 - val_loss: 0.4632\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4323 - val_loss: 0.4611\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4602\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.4269 - val_loss: 0.4572\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4557\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4538\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4524\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4208 - val_loss: 0.4503\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 901us/step - loss: 0.4206 - val_loss: 0.4480\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.4195 - val_loss: 0.4464\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4177 - val_loss: 0.4459\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.4161 - val_loss: 0.4437\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4145 - val_loss: 0.4426\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4138 - val_loss: 0.4404\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.4135 - val_loss: 0.4389\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4368\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 912us/step - loss: 0.4095 - val_loss: 0.4361\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 888us/step - loss: 0.4077 - val_loss: 0.4349\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4329\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.4313\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 980us/step - loss: 0.4055 - val_loss: 0.4302\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4037 - val_loss: 0.4293\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4048 - val_loss: 0.4281\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4271\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4253\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4001 - val_loss: 0.4245\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 915us/step - loss: 0.3991 - val_loss: 0.4234\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 905us/step - loss: 0.3981 - val_loss: 0.4223\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 908us/step - loss: 0.3973 - val_loss: 0.4216\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 953us/step - loss: 0.3976 - val_loss: 0.4203\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 925us/step - loss: 0.3961 - val_loss: 0.4187\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4186\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 895us/step - loss: 0.3938 - val_loss: 0.4177\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.3930 - val_loss: 0.4166\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.3926 - val_loss: 0.4151\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.3923 - val_loss: 0.4147\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4151\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4133\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4128\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.4123\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4121\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4117\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.3875 - val_loss: 0.4094\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.3885 - val_loss: 0.4088\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4091\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4078\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4071\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.3841 - val_loss: 0.4062\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 919us/step - loss: 0.3844 - val_loss: 0.4067\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.4052\n",
      "73/73 [==============================] - 0s 684us/step - loss: 0.4110\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B2BD90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819B2BD90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "277/291 [===========================>..] - ETA: 0s - loss: 1.7972WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BDD30D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BDD30D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.0877\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8677 - val_loss: 0.8948\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7769 - val_loss: 0.8277\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7299 - val_loss: 0.7841\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6956 - val_loss: 0.7459\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6674 - val_loss: 0.7166\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6437 - val_loss: 0.6893\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.6219 - val_loss: 0.6714\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.6036 - val_loss: 0.6476\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5871 - val_loss: 0.6310\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.6202\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.6032\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 939us/step - loss: 0.5476 - val_loss: 0.5914\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5369 - val_loss: 0.5819\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.5320 - val_loss: 0.5685\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.5196 - val_loss: 0.5670\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.5133 - val_loss: 0.5535\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.5421\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5350\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4933 - val_loss: 0.5310\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4874 - val_loss: 0.5229\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4830 - val_loss: 0.5204\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 970us/step - loss: 0.4788 - val_loss: 0.5140\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.4748 - val_loss: 0.5096\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4711 - val_loss: 0.5144\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4683 - val_loss: 0.5042\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4664 - val_loss: 0.5027\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4619 - val_loss: 0.4939\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4600 - val_loss: 0.4915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.4582 - val_loss: 0.4995\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4853\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4527 - val_loss: 0.4963\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4798\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 977us/step - loss: 0.4493 - val_loss: 0.4815\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 932us/step - loss: 0.4479 - val_loss: 0.4803\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4450 - val_loss: 0.4747\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4773\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4721\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4746\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.4379 - val_loss: 0.4695\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4671\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4706\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4682\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4704\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 973us/step - loss: 0.4309 - val_loss: 0.4593\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 984us/step - loss: 0.4289 - val_loss: 0.4651\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 967us/step - loss: 0.4276 - val_loss: 0.4593\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4261 - val_loss: 0.4548\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4548\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4527\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4231 - val_loss: 0.4530\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4204 - val_loss: 0.4507\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4200 - val_loss: 0.4496\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4482\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.4188 - val_loss: 0.4500\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4164 - val_loss: 0.4445\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4437\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 963us/step - loss: 0.4143 - val_loss: 0.4424\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 956us/step - loss: 0.4137 - val_loss: 0.4465\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 990us/step - loss: 0.4115 - val_loss: 0.4415\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 960us/step - loss: 0.4119 - val_loss: 0.4383\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4405\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 929us/step - loss: 0.4079 - val_loss: 0.4371\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 946us/step - loss: 0.4075 - val_loss: 0.4374\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4055 - val_loss: 0.4355\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 936us/step - loss: 0.4051 - val_loss: 0.4354\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4369\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4314\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4028 - val_loss: 0.4318\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.4009 - val_loss: 0.4312\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4300\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4271\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4271\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 942us/step - loss: 0.3979 - val_loss: 0.4270\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4249\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4236\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4226\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4219\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4218\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4213\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4226\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4186\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4214\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4188\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4162\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4164\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4177\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.3873 - val_loss: 0.4163\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4144\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4137\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.3874 - val_loss: 0.4121\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 966us/step - loss: 0.3845 - val_loss: 0.4115\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4119\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 987us/step - loss: 0.3832 - val_loss: 0.4110\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4104\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4102\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4086\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 949us/step - loss: 0.3806 - val_loss: 0.4096\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4074\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4069\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.4080\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381E2BDC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381E2BDC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/291 [==========================>...] - ETA: 0s - loss: 3.5368WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A38598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023819A38598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.4199 - val_loss: 2.2472\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.6639 - val_loss: 1.3981\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.1317 - val_loss: 1.0410\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8913 - val_loss: 0.8612\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7670 - val_loss: 0.7741\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7119 - val_loss: 0.7321\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6787 - val_loss: 0.7082\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6585 - val_loss: 0.6911\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6441 - val_loss: 0.6772\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.6642\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6211 - val_loss: 0.6526\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6419\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6319\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.6225\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5831 - val_loss: 0.6134\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5754 - val_loss: 0.6050\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5678 - val_loss: 0.5967\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.5892\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5542 - val_loss: 0.5818\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5471 - val_loss: 0.5749\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5683\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5618\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5558\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 0.5498\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5440\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5139 - val_loss: 0.5386\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.5336\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 0.5286\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.5240\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.5193\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4932 - val_loss: 0.5154\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.5114\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.5070\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.5034\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4780 - val_loss: 0.4996\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4967\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4720 - val_loss: 0.4928\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4897\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.4869\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4838\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4808\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.4780\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4748\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.4724\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4702\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4678\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4652\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4640\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4614\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.4592\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4575\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4552\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4534\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4517\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4500\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4483\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4460\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4444\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4434\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4415\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4396\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4381\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4364\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4349\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4337\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4324\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4315\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4293\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4280\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4266\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4238\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4229\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4222\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4202\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4192\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4181\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4167\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4160\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4141\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4131\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4118\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4116\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4095\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.4087\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.4077\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4066\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4056\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4044\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4035\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4023\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4017\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4011\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3999\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3985\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3976\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3965\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3959\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3951\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3945\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3556\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CF53488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CF53488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "256/291 [=========================>....] - ETA: 0s - loss: 3.7312WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.5614 - val_loss: 2.1878\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.5545 - val_loss: 1.2631\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0546 - val_loss: 0.9844\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8683 - val_loss: 0.8652\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7761 - val_loss: 0.8022\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7300 - val_loss: 0.7655\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7008 - val_loss: 0.7397\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6788 - val_loss: 0.7196\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6583 - val_loss: 0.7017\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6426 - val_loss: 0.6854\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6302 - val_loss: 0.6707\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.6567\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 0.6438\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.6310\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5794 - val_loss: 0.6194\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.6085\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5596 - val_loss: 0.5983\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5487 - val_loss: 0.5883\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5410 - val_loss: 0.5791\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.5703\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5624\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5178 - val_loss: 0.5544\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5468\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5029 - val_loss: 0.5404\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4969 - val_loss: 0.5332\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.5271\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4858 - val_loss: 0.5209\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.5154\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.5099\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4703 - val_loss: 0.5050\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.5003\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4959\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4910\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4872\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4835\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4800\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4770\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4740\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4701\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4676\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4646\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4620\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.4594\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4568\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4546\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4520\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4501\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4478\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4457\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4441\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4412\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4398\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4376\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4360\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4340\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4327\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4313\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.4289\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4272\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4261\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4242\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.4232\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4214\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4200\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4188\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4181\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4160\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4153\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.4133\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.4107\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4074\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4066\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.4048\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.4037\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4025\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.4018\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.4011\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3999\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3987\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.3980\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3975\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3971\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3953\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3947\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3937\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3932\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3924\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3919\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3913\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3905\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3897\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3886\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3874\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3865\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3864\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.3732\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381D115E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381D115E18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "273/291 [===========================>..] - ETA: 0s - loss: 3.1103WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BAA1A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381BAA1A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 3.0154 - val_loss: 1.8209\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.3478 - val_loss: 1.1284\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.8895\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7679 - val_loss: 0.7806\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.7307\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6650 - val_loss: 0.7002\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6405 - val_loss: 0.6792\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 0.6611\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 0.6453\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5895 - val_loss: 0.6300\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.6160\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.6030\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5523 - val_loss: 0.5914\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5410 - val_loss: 0.5801\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5698\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5601\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5141 - val_loss: 0.5516\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5438\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.5358\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.5284\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.5223\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.5161\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.5105\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.5055\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4674 - val_loss: 0.5005\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4961\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4925\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4884\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4846\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4809\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4782\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4753\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4731\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4689\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4664\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4634\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4623\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4590\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4564\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4545\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4519\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4500\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4482\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4460\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4452\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4422\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4403\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4399\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4368\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4352\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4334\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4333\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4303\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.4298\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4278\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4262\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4245\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.4237\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4224\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4204\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4194\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4181\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.4167\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4158\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4150\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4139\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4134\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4109\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4098\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4083\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4075\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4068\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4061\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4045\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4034\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.4025\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.4016\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4007\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3995\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3984\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3976\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3970\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3964\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3954\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3944\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3938\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3926\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3918\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3912\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3901\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3899\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3890\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3883\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3874\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3868\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3869\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3857\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3850\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3843\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3836\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3651\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238180D2840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238180D2840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "284/291 [============================>.] - ETA: 0s - loss: 2.6730WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381B6F3510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 2.6381 - val_loss: 1.3811\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0596 - val_loss: 1.0416\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8612 - val_loss: 0.9083\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7765 - val_loss: 0.8394\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7319 - val_loss: 0.8011\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7024 - val_loss: 0.7784\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6810 - val_loss: 0.7545\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6638 - val_loss: 0.7373\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6494 - val_loss: 0.7200\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6380 - val_loss: 0.7066\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6263 - val_loss: 0.6912\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6785\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6661\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5915 - val_loss: 0.6569\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5821 - val_loss: 0.6449\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5731 - val_loss: 0.6345\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.6240\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5571 - val_loss: 0.6150\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5497 - val_loss: 0.6058\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5965\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5886\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5820\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5215 - val_loss: 0.5732\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5161 - val_loss: 0.5670\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5590\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5522\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.5459\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4942 - val_loss: 0.5397\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.5354\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4866 - val_loss: 0.5288\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.5239\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4782 - val_loss: 0.5185\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4718 - val_loss: 0.5133\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.5084\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4640 - val_loss: 0.5038\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.5000\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4957\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4553 - val_loss: 0.4928\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4878\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4837\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4799\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4769\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4744\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4702\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4675\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4645\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4617\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4588\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4562\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4537\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4510\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4492\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4466\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4442\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4421\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4399\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4377\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4368\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.4340\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4320\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4302\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4285\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4273\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4256\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4237\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.4221\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4209\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4192\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4179\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4168\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4152\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4142\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4122\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4116\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4104\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4092\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4076\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4065\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4063\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4051\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4039\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4028\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.4018\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4012\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4012\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3994\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3989\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3979\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3975\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3959\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3952\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3946\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3936\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3932\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3925\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3920\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3913\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3906\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3898\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3896\n",
      "73/73 [==============================] - 0s 615us/step - loss: 0.3838\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819507B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000023819507B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "270/291 [==========================>...] - ETA: 0s - loss: 3.3191WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEE2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 3.2354 - val_loss: 1.9608\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.4999 - val_loss: 1.2495\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.0707 - val_loss: 0.9857\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.8730 - val_loss: 0.8516\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7698 - val_loss: 0.7914\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.7199 - val_loss: 0.7591\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6922 - val_loss: 0.7367\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6743 - val_loss: 0.7202\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6543 - val_loss: 0.7042\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6410 - val_loss: 0.6902\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6262 - val_loss: 0.6770\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6649\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6034 - val_loss: 0.6533\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5921 - val_loss: 0.6426\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.6322\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5741 - val_loss: 0.6221\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5659 - val_loss: 0.6125\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5564 - val_loss: 0.6036\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.5949\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5873\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5332 - val_loss: 0.5793\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 0.5718\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5648\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5134 - val_loss: 0.5587\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5519\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 0.5454\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.5399\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5346\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.5285\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.5227\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.5182\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.5149\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.5089\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.5053\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.5010\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.4969\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4925\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4509 - val_loss: 0.4895\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4848\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4834\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4792\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4764\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4362 - val_loss: 0.4726\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4703\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4673\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4649\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4630\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4598\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4570\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4543\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4526\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4498\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4466\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4454\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4423\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4400\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4380\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4363\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4336\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4009 - val_loss: 0.4319\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4298\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4282\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4260\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4250\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4233\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4226\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4195\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4211\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4185\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4164\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4150\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.4132\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.4126\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4116\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4099\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4094\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4076\n",
      "Epoch 78/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.4075\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4050\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.4055\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4038\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.4020\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4008\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.4000\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3987\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3977\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3980\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3962\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3956\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.3952\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3946\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3933\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3932\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3917\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3906\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3896\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3892\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3893\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3880\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3881\n",
      "73/73 [==============================] - 0s 533us/step - loss: 0.3960\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BDD37B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BDD37B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "227/291 [======================>.......] - ETA: 0s - loss: 1.0127WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198D9C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000238198D9C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9245 - val_loss: 0.6530\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.4986\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4597\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4013\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3872\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4159\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.4054\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3684\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3789\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3646\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3503\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.4113\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3767\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3574\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.4590\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3371\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3985\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3360\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3290\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.4094\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3294\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3256\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3751\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3334\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3169\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3153\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.3173\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.3209\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.5370\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3214\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 982us/step - loss: 0.2960 - val_loss: 0.3137\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3516\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.3125\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3315\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3159\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3072\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3260\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3111\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3287\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.3101\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.3336\n",
      "73/73 [==============================] - 0s 601us/step - loss: 0.3056\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CE8BAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381CE8BAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "218/291 [=====================>........] - ETA: 0s - loss: 1.2845WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381979E6A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381979E6A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.1080 - val_loss: 0.6118\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 0.5160\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.4764\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4489\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4358\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4214\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4089\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4103\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3959\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3846\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3990\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3758\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3791\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3776\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3638\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3647\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3609\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3557\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3576\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3543\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3475\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3409\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3408\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3523\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.4343\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3352\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3826\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3296\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3311\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3288\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.4096\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.4663\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3251\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.3255\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3219\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3660\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3298\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.3277\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3541\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3278\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3222\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.3238\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3405\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.3332\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3542\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3217\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.3908\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3231\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.2987\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B9FBE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381B9FBE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "224/291 [======================>.......] - ETA: 0s - loss: 1.3764WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381CEEB1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 1.2178 - val_loss: 0.6610\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5518 - val_loss: 0.5377\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.4855\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4511\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4178\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4108\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3958\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3801\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3855\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3665\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3832\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.3798\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3715\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3533\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3730\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.3495\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3518\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3440\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3368\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3432\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3380\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3871\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3324\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3332\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3300\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3508\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3225\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3203\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.3219\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.3190\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3170\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3273\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.3200\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.3204\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 0.3330\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.3167\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3093\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.3784\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.3111\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3119\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.3248\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2807 - val_loss: 0.3386\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.3396\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3362\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.3249\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3013\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2754 - val_loss: 0.3064\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.3001\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.2713 - val_loss: 0.3097\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2731 - val_loss: 0.3017\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2704 - val_loss: 0.3003\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.3300\n",
      "73/73 [==============================] - 0s 588us/step - loss: 0.3442\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BAA1D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002381BAA1D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "218/291 [=====================>........] - ETA: 0s - loss: 1.1203WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023816D08620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000023816D08620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9964 - val_loss: 0.6465\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5544 - val_loss: 0.5609\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.5146\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4310\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4092\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3993\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3939\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3855\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3799\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3636\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.3425 - val_loss: 0.3641\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3640\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.4017\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3567\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3440\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.3448\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3537\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.3169 - val_loss: 0.3740\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3795\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3326\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3316\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3327\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3321\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3377\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.4119\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.3982\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3361\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.3189\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3807\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.3255\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.3285\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.3278\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.3208\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3251\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3266\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.3216\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3148\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 0.3402\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.3100\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.3581\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 0.3217\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2776 - val_loss: 0.3189\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.3169\n",
      "73/73 [==============================] - 0s 614us/step - loss: 0.3151\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238199599D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000238199599D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "225/291 [======================>.......] - ETA: 0s - loss: 1.0205WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381A4C5C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002381A4C5C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.9330 - val_loss: 0.6281\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 994us/step - loss: 0.5421 - val_loss: 0.5223\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4645\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4389\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4179\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3959\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.4180\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3826\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.4004\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3734\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3640\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4191\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3764\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.4205\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3504\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3556\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3945\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3498\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.4135\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3388\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3401\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3556\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3432\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3352\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3585\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 997us/step - loss: 0.3022 - val_loss: 0.3514\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.3436\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3291\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.3175\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3358\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3236\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.3327\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.3340\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3181\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.3300\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4480\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3136\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 0.3139\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.3184\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3163\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.3130\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2737 - val_loss: 0.3035\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3258\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3086\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3054\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2691 - val_loss: 0.3192\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3373\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.8951\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3293\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2725 - val_loss: 0.4012\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.3076\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3155\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 0.3030\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3373\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2643 - val_loss: 0.3189\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3018\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.2992\n",
      "73/73 [==============================] - 0s 589us/step - loss: 0.3100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023819DECF98>, as the constructor either does not set or modifies parameter layer_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4f76913f1e69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m random_search_cv.fit(x_train_scaled, y_train, epochs=100,\n\u001b[0;32m     18\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_valid_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     callbacks = callbacks)\n\u001b[0m",
      "\u001b[1;32mD:\\Tools\\Anaconda\\Anaconda3\\envs\\py36_tensorflow2.0_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 736\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda\\Anaconda3\\envs\\py36_tensorflow2.0_gpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     81\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023819DECF98>, as the constructor either does not set or modifies parameter layer_size"
     ]
    }
   ],
   "source": [
    "# 2.定义参数集合\n",
    "from scipy.stats import reciprocal\n",
    "# f(x) = 1/(x*log(b/a))  a <= x <= b\n",
    "\n",
    "param_distribution={\n",
    "    \"hidden_layers\":[1,2,3,4],\n",
    "    \"layer_size\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search_cv= RandomizedSearchCV(sklearn_model, \n",
    "                                    param_distribution,\n",
    "                                    n_iter=10,\n",
    "                                    n_jobs =1)\n",
    "random_search_cv.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data= (x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import reciprocal\n",
    "# reciprocal.rvs(1e-4, 1e-2, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 3, 'layer_size': 82, 'learning_rate': 0.007469045451049146}\n",
      "-0.31188341975212097\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-51daeb1a4371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 查看最好的model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)\n",
    "print(random_search_cv.best_estimator_) # 查看最好的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random_search_cv.best_estimator_.model\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_tensorflow2.0_gpu",
   "language": "python",
   "name": "py36_tensorflow2.0_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
